{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk through the process of cleaning and combining the data from IPEDS into a data set for analysis. The final form at the end will be a pandas panel (appropriately serialized and stored) which contains the following information:\n",
    "\n",
    "* for each year between 1984 and 2013 (the items axis)\n",
    "    * for each institution (the major axis)\n",
    "        * institutional characteristics:\n",
    "            1. The IPEDS unit ID\n",
    "            2. the institution name\n",
    "            3. the sector (public/private; for profit/nonprofit; less than 2 year/2 year/4+ year)\n",
    "            4. latitude and longitude (for mapping purposes)\n",
    "        * Fall Enrollments:\n",
    "            1. Undergraduate FTE\n",
    "            2. Ethnicities will go here if I decide I need them\n",
    "            3. Incoming test scores will go here if I can find them (I've seen them for later years, but not for earlier years)\n",
    "        * Faculty and staff characteristics:\n",
    "            1. number of faculty in each academic rank\n",
    "            2. median salaries\n",
    "            3. percentages with terminal degrees\n",
    "            4. size of administrative staff\n",
    "            5. non-faculty staff salary information (by job type? or something?)\n",
    "        * Finances\n",
    "            1. size of the endowment (mostly for private, non-profit institutions)\n",
    "            2. tuition revenues\n",
    "            3. State and Federal appropriations/grants\n",
    "            4. research revenues\n",
    "            5. instructional costs\n",
    "            6. other costs\n",
    "        * Admissions\n",
    "            1. Number of applicants\n",
    "            2. Number of admits\n",
    "            3. number of enrollees\n",
    "        * Retention\n",
    "            1. First year retention\n",
    "            2. other retention numbers, if available\n",
    "            3. 4 year completion rate\n",
    "            4. 6 year completion rate\n",
    "        * Tuition, financial aid and student debt\n",
    "            1. sticker price (tuition only)\n",
    "            2. fully loaded cost\n",
    "            3. discount rate\n",
    "            4. percentage of students receiving aid\n",
    "            5. average award amount\n",
    "            6. average student debt\n",
    "\n",
    "That's an impressively long list. The variables are spread across several files (and different files for different years). We'll do each category separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Institutional Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(csvfile, columns, charcols):\n",
    "    raw = pd.read_csv(csvfile, encoding='latin-1')\n",
    "    # standardize column names to uppercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    \n",
    "    # only transform the columns if we actually have them\n",
    "    # they may not be present in every year\n",
    "    intersect = list(set(charcols) & set(prepped.columns))\n",
    "    for col in intersect:\n",
    "        prepped[col] = prepped[col].str.strip()\n",
    "    \n",
    "    cooked = pd.DataFrame(prepped, columns=columns)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the variables we want\n",
    "columns = ['instnm', 'sector', 'act', 'latitude', 'longitud']\n",
    "\n",
    "# these columns have string values; we want to trim extra whitespace.\n",
    "charcols = ['instnm', 'act']\n",
    "\n",
    "# files for institutional characteristics\n",
    "csvfiles = {1984: 'ic1984.csv',\n",
    "            1985: 'ic1985.csv',\n",
    "            1986: 'ic1986_a.csv',\n",
    "            1987: 'ic1987_a.csv',\n",
    "            1988: 'ic1988_a.csv',\n",
    "            1989: 'ic1989_a.csv',\n",
    "            1990: 'ic90hd.csv',\n",
    "            1991: 'ic1991_hdr.csv',\n",
    "            1992: 'ic1992_a.csv',\n",
    "            1993: 'ic1993_a.csv',\n",
    "            1994: 'ic1994_a.csv',\n",
    "            1995: 'ic9596_a.csv',\n",
    "            1996: 'ic9697_a.csv',\n",
    "            1997: 'ic9798_hdr.csv',\n",
    "            1998: 'ic98hdac.csv',\n",
    "            1999: 'ic99_hd.csv',\n",
    "            2000: 'fa2000hd.csv',\n",
    "            2001: 'fa2001hd.csv',\n",
    "            2002: 'hd2002.csv',\n",
    "            2003: 'hd2003.csv',\n",
    "            2004: 'hd2004.csv',\n",
    "            2005: 'hd2005.csv',\n",
    "            2006: 'hd2006.csv',\n",
    "            2007: 'hd2007.csv',\n",
    "            2008: 'hd2008.csv',\n",
    "            2009: 'hd2009.csv',\n",
    "            2010: 'hd2010.csv',\n",
    "            2011: 'hd2011.csv',\n",
    "            2012: 'hd2012.csv',\n",
    "            2013: 'hd2013.csv'}\n",
    "\n",
    "dataframes = {}\n",
    "for year in csvfiles.keys():\n",
    "    dataframes[year] = process('../data/' + csvfiles[year], columns, charcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with NaNs, take a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fall enrollments\n",
    "\n",
    "Unfortunately, what is reported in this section and how it is reported have changed significantly over the 30 year period we're studying. Some distinctions, like age categories, were added, and others, like the year in school, have been removed. Breakdown by ethnicity is available most years, but not all (*e.g.*, 1985).\n",
    "\n",
    "I'll keep things relatively simple and look at full-time undergraduate men, full-time undergraduate women, part-time undergraduate men, part-time undergraduate women, and grand total of all students. The data is reported as long form panel data, so we'll have to do some grouping to extract the pieces we want into columns for a single unitid.\n",
    "\n",
    "A little modification to our process routine will allow for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process(csvfile, columns, charcols=[], groupcolumn=None,\n",
    "            grouplabels=None, collabels=None):\n",
    "    raw = pd.read_csv(csvfile, encoding='latin-1')\n",
    "    # standardize column names to uppercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "\n",
    "    if groupcolumn is not None:\n",
    "        if grouplabels is None or collabels is None:\n",
    "            raise KeyError('Specify labels for the desired groups and columns.')\n",
    "        grouped = prepped.groupby(groupcolumn)\n",
    "        merged = None\n",
    "        for value, label in grouplabels:\n",
    "            groupedcols = {}\n",
    "            for key, val in collabels.items():\n",
    "                groupedcols[key] = label + val\n",
    "            if merged is None:\n",
    "                merged = pd.DataFrame(grouped.get_group(value), columns=groupedcols.keys())\n",
    "                merged.columns = groupedcols.values()\n",
    "            else:\n",
    "                labeldf = pd.DataFrame(grouped.get_group(value), columns=groupedcols.keys())\n",
    "                labeldf.columns = groupedcols.values()\n",
    "                merged = pd.merge(merged, labeldf, left_index=True, right_index=True)\n",
    "        prepped = merged\n",
    "        \n",
    "    \n",
    "    # only transform the columns if we actually have them\n",
    "    # they may not be present in every year\n",
    "    intersect = list(set(charcols) & set(prepped.columns))\n",
    "    for col in intersect:\n",
    "        prepped[col] = prepped[col].str.strip()\n",
    "    \n",
    "    cooked = pd.DataFrame(prepped, columns=columns)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to set up a dictionary to give `process` what it needs: the csv file name, the name of the column to group on, the labels and values of the groups, and a translation for the columns to extract.  I'm choosing to pass these things in rather than hardcode them for a couple of reasons. First, I think this same approach will be necessary when looking at the faculty section, and I'd prefer not to repeat myself. Second, most of these things change over the course of the data.  \n",
    "\n",
    "I'm actually able to group over the same column in every case, even though in about 2000 another, more detailed breakdown was added. Also, in 2008, the names of the columns I want to extract changed. An additional wrinkle is that up until 2008, they didn't report total students; they kept it broken out in total men and total women. After 2008, they have an additional column which is the sum of the other two. Rather than try to take it if it's there, I'm just going to calculate it after the fact for every case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the variables we want to extract:\n",
    "# FTUGM : Full-time undergraduate men\n",
    "# FTUGW : Full-time undergraduate women\n",
    "# PTUGM : Part-time undergraduate men\n",
    "# PTUGW : Part-time undergraduate women\n",
    "# ALLM : Total Men (including graduate and professional students)\n",
    "# ALLW : Total Women (including graduate and professional students)\n",
    "columns = ['ftugm', 'ftugw', 'ptugm', 'ptugw', 'allm', 'allw']\n",
    "\n",
    "# No string values in this set\n",
    "charcols = []\n",
    "\n",
    "agg84 = {'groupcolumn':'line',\n",
    "         'grouplabels':((1,'ftug'), ((15,'ptug')), ((29,'all'))),\n",
    "         'collabels': {'efrace15':'m', 'efrace16':'w'}}\n",
    "\n",
    "agg86 = {'groupcolumn':'line',\n",
    "         'grouplabels':((8,'ftug'), ((22,'ptug')), ((29,'all'))),\n",
    "         'collabels': {'efrace15':'m', 'efrace16':'w'}}\n",
    "\n",
    "agg08 = {'groupcolumn':'line',\n",
    "         'grouplabels':((8,'ftug'), ((22,'ptug')), ((29,'all'))),\n",
    "         'collabels': {'eftotlm':'m', 'eftotlw':'w'}}\n",
    "\n",
    "\n",
    "# files and columns for fall enrollments\n",
    "years = {1984: {'csv':'ef1984.csv',\n",
    "                'aggregation':agg84},\n",
    "         1985: {'csv':'ef1985.csv',\n",
    "                'aggregation':agg84},\n",
    "         1986: {'csv':'ef1986_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1987: {'csv':'ef1987_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1988: {'csv':'ef1988_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1989: {'csv':'ef1989_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1990: {'csv':'ef90_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1991: {'csv':'ef1991_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1992: {'csv':'ef1992_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1993: {'csv':'ef1993_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1994: {'csv':'ef1994_acp.csv',\n",
    "                'aggregation':agg86},\n",
    "         1995: {'csv':'ef95_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1996: {'csv':'ef96_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1997: {'csv':'ef97_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1998: {'csv':'ef98_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1999: {'csv':'ef99_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         2000: {'csv':'ef2000a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2001: {'csv':'ef2001a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2002: {'csv':'ef2002a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2003: {'csv':'ef2003a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2004: {'csv':'ef2004a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2005: {'csv':'ef2005a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2006: {'csv':'ef2006a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2007: {'csv':'ef2007a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2008: {'csv':'ef2008a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2009: {'csv':'ef2009a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2010: {'csv':'ef2010a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2011: {'csv':'ef2011a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2012: {'csv':'ef2012a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2013: {'csv':'ef2013a.csv',\n",
    "                'aggregation':agg08},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "efdataframes = {}\n",
    "for year, info in years.items():\n",
    "    efdataframes[year] = process('../data/' + info['csv'], columns, charcols,\n",
    "                                groupcolumn=info['aggregation']['groupcolumn'],\n",
    "                                grouplabels=info['aggregation']['grouplabels'],\n",
    "                                collabels=info['aggregation']['collabels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute totals and ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for enroldf in efdataframes.values():\n",
    "    # totals for full time, part time, and all students\n",
    "    enroldf['ftugt'] = enroldf['ftugm'] + enroldf['ftugw']\n",
    "    enroldf['ptugt'] = enroldf['ptugm'] + enroldf['ptugw']\n",
    "    enroldf['allt'] = enroldf['allm'] + enroldf['allw']\n",
    "    \n",
    "    # male/total fraction for FTUG:\n",
    "    enroldf['ftmf'] = enroldf['ftugm']/enroldf['ftugt']\n",
    "    \n",
    "    # FT undergraduate fraction:\n",
    "    enroldf['ugfrac'] = enroldf['ftugt']/enroldf['allt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge into existing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, yeardf in dataframes.items():\n",
    "    dataframes[year] = pd.merge(yeardf, efdataframes[year], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframes[2013].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Faculty and staff\n",
    "\n",
    "IPEDS has three different surveys that deal with faculty and staff:\n",
    "* Instructional staff/Salaries.  This survey is the most complete (in terms of years of availability), but has some significant drawbacks. The 2012 and 2013 surveys have non-instructional staff included, but none of the other years do. The surveys between 2005 and 2011 include people on contracts less than 9 months (*i.e.*, adjuncts) but other years don't. Fringe benefits were included up until 2010, but apparently not after that. Furthermore, 9 and 12 month contracts are reported separately. While there may be some deeply meaningful reason for doing so, it makes things a little more difficult for me.\n",
    "* Fall Staff. Available from 1987 onward in odd years, and every year after 2001. This includes noninstructional staff in a whole host of categories, but doesn't include any salary data.\n",
    "* Employees by Assigned Position. From 2001 on. Has many more categories than either of the others. Includes tenure status but not faculty rank.\n",
    "\n",
    "If I want to cover the whole range of years (which I do), I can get closest by using the first of these, which means largely ignoring noninstructional staff and adjuncts and dealing with the 9/12 month issues.  I'll do that for a first pass, at least.\n",
    "\n",
    "The files seem to come in two flavors: wide and long. The long flavor has a variable for academic rank (and another for contract type) which we can group over.  The wide flavor just has all of the variables in a single row.\n",
    "* wide: 1987, 1989-1998 \n",
    "* long: 1984, 1985, 1999, 2001-2013 \n",
    "* missing: 1986, 1988, 2000\n",
    "\n",
    "We process the long flavor files like the fall enrolment, above.  The wide ones are easier; they're like the institutional characteristics we did first.\n",
    "\n",
    "The last thing to do before we actually process is to decide which columns we want to keep. We have two sexes, between two and four contract durations, six academic ranks (full, associate, assistant, instructor, lecturer, and no rank), and three tenure statuses (tenured, tenure track, and non-tenure track), for a total of up to 144 columns. That's clearly too many, and in fact, some of the years don't have that many.\n",
    "\n",
    "If I ignore tenure status (which isn't reported every year, anyway), and gender distribution (there are people better qualified than I to study diversity issues), and contract length, then I'm down to six categories with two variables each (number of people and salary outlay).  Monthly salary may be a more meaningful number, but I don't really care at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wide format years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wide format\n",
    "# 1987-1997\n",
    "aggregation = {'fullcount':['a4', 'a39', 'a79', 'a114'],\n",
    "               'fulloutlay':['a5', 'a40', 'a80', 'a115'],\n",
    "               'assoccount':['a9', 'a44', 'a84', 'a119'],\n",
    "               'assocoutlay':['a10', 'a45', 'a85', 'a120'],\n",
    "               'assistcount':['a14', 'a49', 'a89', 'a124'],\n",
    "               'assistoutlay':['a15', 'a50', 'a90', 'a125'],\n",
    "               'instrcount':['a19', 'a54', 'a94', 'a129'],\n",
    "               'instroutlay':['a20', 'a55', 'a95', 'a130'],\n",
    "               'lectcount':['a24', 'a59', 'a99', 'a134'],\n",
    "               'lectoutlay':['a25', 'a60', 'a100', 'a135'],\n",
    "               'norankcount':['a29', 'a64', 'a104', 'a139'],\n",
    "               'norankoutlay':['a30', 'a65', 'a105', 'a140']}\n",
    "\n",
    "# 1998\n",
    "agg98 = {'fullcount':['saa014', 'saa084', 'saa164', 'saa234'],\n",
    "         'fulloutlay':['saa015', 'saa085', 'saa165', 'saa235'],\n",
    "         'assoccount':['saa024', 'saa094', 'saa174', 'saa244'],\n",
    "         'assocoutlay':['saa025', 'saa095', 'saa175', 'saa245'],\n",
    "         'assistcount':['saa034', 'saa104', 'saa184', 'saa254'],\n",
    "         'assistoutlay':['saa035', 'saa105', 'saa185', 'saa255'],\n",
    "         'instrcount':['saa044', 'saa114', 'saa194', 'saa264'],\n",
    "         'instroutlay':['saa045', 'saa115', 'saa195', 'saa265'],\n",
    "         'lectcount':['saa054', 'saa124', 'saa204', 'saa274'],\n",
    "         'lectoutlay':['saa055', 'saa125', 'saa205', 'saa275'],\n",
    "         'norankcount':['saa064', 'saa134', 'saa214', 'saa284'],\n",
    "         'norankoutlay':['saa065', 'saa135', 'saa215', 'saa285']}\n",
    "\n",
    "wideyears = {1987: {'csv':'sal1987_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1989: {'csv':'sal1989_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1990: {'csv':'sal90_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1991: {'csv':'sal1991_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1992: {'csv':'sal1992_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1993: {'csv':'sal1993_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1994: {'csv':'sal1994_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1995: {'csv':'sal95_a_1.csv',\n",
    "                   'agg':aggregation},\n",
    "             1996: {'csv':'sal96_a_1.csv',\n",
    "                   'agg':aggregation},\n",
    "             1997: {'csv':'sal97_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1998: {'csv':'sal98_a.csv',\n",
    "                   'agg':agg98}}\n",
    "\n",
    "def process_wide(csvfile, aggregation):\n",
    "    raw = pd.read_csv(csvfile, encoding='latin-1')\n",
    "    # standardize column names to lowercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    \n",
    "    for aggregated, aggcols in aggregation.items():\n",
    "        prepped[aggregated] = prepped[aggcols].sum(axis=1)\n",
    "    \n",
    "    cooked = pd.DataFrame(prepped, columns=aggregation.keys()).fillna(0)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facultydfs = {}\n",
    "for year, yeardict in wideyears.items():\n",
    "    facultydfs[year] = process_wide('../data/'+yeardict['csv'], yeardict['agg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create empty data frames for missing years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missingyears = [1986, 1988, 2000]\n",
    "for year in missingyears:\n",
    "    facultydfs[year] = pd.DataFrame(columns=aggregation.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do the long format years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg84 = {'count':['saa1', 'saa4'],\n",
    "         'outlay':['saa2', 'saa5'],\n",
    "         'group':'line',\n",
    "         'vals':{'full':[1,8],\n",
    "                 'assoc':[2,9],\n",
    "                 'assist':[3,10],\n",
    "                 'instr':[4,11],\n",
    "                 'lect':[5,12],\n",
    "                 'norank':[6,13]}}\n",
    "\n",
    "# in 1999, the survey separated academic rank and contract length into \n",
    "# two line items\n",
    "agg99 = {'count':['empcntm', 'empcntw'],\n",
    "         'outlay':['outlaym', 'outlayw'],\n",
    "         'group':['contract','arank'],\n",
    "         'vals':{'full':[(1,1), (2,1)],\n",
    "                 'assoc':[(1,2), (2,2)],\n",
    "                 'assist':[(1,3), (2,3)],\n",
    "                 'instr':[(1,4), (2,4)],\n",
    "                 'lect':[(1,5), (2,5)],\n",
    "                 'norank':[(1,6), (2,6)]}}\n",
    "\n",
    "# the only survey available from 2001 is a summary, which doesn't separate women and men.\n",
    "# otherwise, it's the same as 99.\n",
    "agg01 = {'count':['empcount',],\n",
    "         'outlay':['outlays',],\n",
    "         'group':['contract','arank'],\n",
    "         'vals':{'full':[(1,1), (2,1)],\n",
    "                 'assoc':[(1,2), (2,2)],\n",
    "                 'assist':[(1,3), (2,3)],\n",
    "                 'instr':[(1,4), (2,4)],\n",
    "                 'lect':[(1,5), (2,5)],\n",
    "                 'norank':[(1,6), (2,6)]}}\n",
    "\n",
    "# in 2012, the contract length went wide while the academic rank stayed long.\n",
    "# also, contract length was split into four categories instead of two.\n",
    "# fortunately, they also include an aggregated column.\n",
    "agg12 = {'count':['satotlt',],\n",
    "         'outlay':['saoutlt',],\n",
    "         'group':'arank',\n",
    "         'vals':{'full':[1,],\n",
    "                 'assoc':[2,],\n",
    "                 'assist':[3,],\n",
    "                 'instr':[4,],\n",
    "                 'lect':[5,],\n",
    "                 'norank':[6,]}}\n",
    "\n",
    "# long format\n",
    "longyears = {1984:{'csv':'sal1984_a.csv',\n",
    "                   'agg':agg84},\n",
    "             1985:{'csv':'sal1985_a.csv',\n",
    "                   'agg':agg84},\n",
    "             1999:{'csv':'sal1999_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2001:{'csv':'sal2001_a_s.csv',\n",
    "                   'agg':agg01},\n",
    "             2002:{'csv':'sal2002_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2003:{'csv':'sal2003_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2004:{'csv':'sal2004_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2005:{'csv':'sal2005_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2006:{'csv':'sal2006_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2007:{'csv':'sal2007_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2008:{'csv':'sal2008_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2009:{'csv':'sal2009_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2010:{'csv':'sal2010_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2011:{'csv':'sal2011_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2012:{'csv':'sal2012_is.csv',\n",
    "                   'agg':agg12},\n",
    "             2013:{'csv':'sal2013_is.csv',\n",
    "                   'agg':agg12}}\n",
    "\n",
    "\n",
    "def process_long(csvfile, aggregation):\n",
    "    raw = pd.read_csv(csvfile, encoding='latin-1')\n",
    "    # standardize column names to lowercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    \n",
    "    grouped = prepped.groupby(aggregation['group'])\n",
    "    collected = {}\n",
    "    for rank,val in aggregation['vals'].items():\n",
    "        groups = []\n",
    "        for subgroup in val:\n",
    "            groups.append(grouped.get_group(subgroup))\n",
    "            \n",
    "        catted = pd.concat(groups)\n",
    "        unitgroups = catted.groupby(level=0)\n",
    "        collected[rank+\"count\"] = unitgroups.sum()[aggregation['count']].sum(axis=1)\n",
    "        collected[rank+\"outlay\"] = unitgroups.sum()[aggregation['outlay']].sum(axis=1)\n",
    "        \n",
    "    cooked = pd.DataFrame(collected).fillna(0)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, yeardict in longyears.items():\n",
    "    facultydfs[year] = process_long('../data/'+yeardict['csv'], yeardict['agg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge into existing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for year, yeardf in dataframes.items():\n",
    "    dataframes[year] = pd.merge(yeardf, facultydfs[year], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finances\n",
    "\n",
    "This is a complicated topic, and I am by no means an expert.  As I see it, there are four important categories of numbers in this section:\n",
    "1. income\n",
    "2. expenses\n",
    "3. assets\n",
    "4. liabilities\n",
    "\n",
    "Unfortunately, the three major types of institution (public, non-profit private, and for-profit private) have significantly different sources of income, and often very different collections of assets and liabilities, as well.  That makes comparisons difficult.  From about 1997 on the three categories of institution have their data in separate files. Before that, the organization of the data is kind of a mess. The first couple years of our range drop everything into a single file, but through most of the 90's, there are a wide array of different files for each year.\n",
    "\n",
    "I'm going to have to select a subset of the possible variables so that I don't drown in them. (There are about 200 different variables for nonprofit institutions in the 2013 data; public institutions (160) and for-profit institutions (40) have fewer). For now, I will focus on six numbers: totals for income, expenses, and debt; amount of income from tuition and fees, value of the endowment at the end of the year, and the amount expended on instructional costs.\n",
    "\n",
    "Assets are kind of a sticky area. Things like land and physical plant are very illiquid, and depend strongly on local market values. On the other hand, for-profit institutions don't have an endowment, as such, but I care less about their finances at this point. If I decide I need some other measure of total assets, or something additional for the for-profit institutions, I'll go back and refactor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping84 = {'totalrevenue':'a20', \n",
    "             'tuitionrevenue':'a01',\n",
    "             'instructionexpense':'b01',\n",
    "             'totalexpense':'b19',\n",
    "             'debt':'d04',\n",
    "             'endowment':'f64'}\n",
    "\n",
    "# total debt and endowment don't seem to be reported in 88.\n",
    "mapping88 = {'totalrevenue':'a163', \n",
    "             'tuitionrevenue':'a013',\n",
    "             'instructionexpense':'b013',\n",
    "             'totalexpense':'b223'}\n",
    "\n",
    "single_files = {1984:{'csv':'f1984.csv',\n",
    "                     'mapping':mapping84},\n",
    "               1985:{'csv':'f1985.csv',\n",
    "                     'mapping':mapping84},\n",
    "               1986:{'csv':'f1986.csv',\n",
    "                     'mapping':mapping84},\n",
    "               1988:{'csv':'f1988.csv',\n",
    "                     'mapping':mapping88}}\n",
    "\n",
    "def process_single_financial(csvfile, mapping):\n",
    "    raw = pd.read_csv(csvfile, encoding='latin-1')\n",
    "    # standardize column names to uppercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    for key, colname in mapping.items():\n",
    "        prepped[key] = prepped[colname]\n",
    "    cooked = pd.DataFrame(prepped, columns=mapping.keys())\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "financedfs = {}\n",
    "for fyear, mapping in single_files.items():\n",
    "    financedfs[fyear] = process_single_financial(\"../data/\"+mapping['csv'], mapping['mapping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expenses87 = {'totalexpense':'b223',\n",
    "              'instructionexpense':'b013'}\n",
    "income87 = {'totalrevenue':'a163',\n",
    "            'tuitionrevenue':'a013'}\n",
    "debt89 = {'debt':'g041'}\n",
    "endowment89 = {'endowment':'h021'}\n",
    "\n",
    "debt93 = {'debt':'g04'}\n",
    "\n",
    "multi_by_category = {1987:{'f1987_a.csv':income87,\n",
    "                           'f1987_b.csv':expenses87},\n",
    "                     1989:{'f1989_a.csv':income87,\n",
    "                           'f1989_b.csv':expenses87,\n",
    "                           'f1989_g.csv':debt89,\n",
    "                           'f1989_h.csv':endowment89},\n",
    "                     1990:{'f8990_a.csv':income87,\n",
    "                           'f8990_b.csv':expenses87},\n",
    "                     1991:{'f1991_a.csv':income87,\n",
    "                           'f1991_b.csv':expenses87,\n",
    "                           'f1991_g.csv':debt89,\n",
    "                           'f1991_h.csv':endowment89},\n",
    "                     1992:{'f1992_a.csv':income87,\n",
    "                           'f1992_b.csv':expenses87,\n",
    "                           'f1992_g.csv':debt89,\n",
    "                           'f1992_h.csv':endowment89},\n",
    "                     1993:{'f1993_a.csv':income87,\n",
    "                           'f1993_b.csv':expenses87,\n",
    "                           'f1993_g.csv':debt93,\n",
    "                           'f1993_h.csv':endowment89},\n",
    "                     1994:{'f1994_a.csv':income87,\n",
    "                           'f1994_b.csv':expenses87,\n",
    "                           'f1994_g.csv':debt93,\n",
    "                           'f1994_h.csv':endowment89},\n",
    "                     1995:{'f9495_a.csv':income87,\n",
    "                           'f9495_b.csv':expenses87,\n",
    "                           'f9495_g.csv':debt93,\n",
    "                           'f9495_h.csv':endowment89},\n",
    "                     1996:{'f9596_a.csv':income87,\n",
    "                           'f9596_b.csv':expenses87,\n",
    "                           'f9596_g.csv':debt93,\n",
    "                           'f9596_h.csv':endowment89}}\n",
    "\n",
    "def process_multi_cat_financial(csvdict):\n",
    "    merged = None\n",
    "    for csvfile, mapping in csvdict.items():\n",
    "        if merged is None:\n",
    "            merged = process_single_financial(\"../data/\" + csvfile, mapping)\n",
    "        else:\n",
    "            temp = process_single_financial(\"../data/\" + csvfile, mapping)\n",
    "            merged = pd.merge(merged, temp, left_index=True, right_index=True)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, cvsdict in multi_by_category.items():\n",
    "    financedfs[year] = process_multi_cat_financial(cvsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "public97 = {'totalexpense':'b223',\n",
    "            'instructionexpense':'b013',\n",
    "            'totalrevenue':'a163',\n",
    "            'tuitionrevenue':'a013',\n",
    "            'debt':'g04',\n",
    "            'endowment':'h021'}\n",
    "\n",
    "private97 = {'totalexpense':'fb12_1',\n",
    "             'instructionexpense':'fb01_1',\n",
    "             'totalrevenue':'fa17_1',\n",
    "             'tuitionrevenue':'fa01_1'}\n",
    "\n",
    "nonprofit98 = {'totalexpense':'f2b12_1',\n",
    "               'instructionexpense':'f2b01_1',\n",
    "               'totalrevenue':'f2a17_1',\n",
    "               'tuitionrevenue':'f2a01_1',\n",
    "               'endowment':'f2d05'}\n",
    "\n",
    "forprofit98 = {'totalexpense':'f3b10_1',\n",
    "               'instructionexpense':'f3b01_1',\n",
    "               'totalrevenue':'f3a10',\n",
    "               'tuitionrevenue':'f3a01'}\n",
    "\n",
    "nonprofit00 = {'totalrevenue':'f2b01',\n",
    "               'tuitionrevenue':'f2d01',\n",
    "               'totalexpense':'f2b02',\n",
    "               'instructionexpense':'f2e011',\n",
    "               'endowment':'f2a01'}\n",
    "\n",
    "forprofit00 = {'totalexpense':'f3b02',\n",
    "               'instructionexpense':'f3e01',\n",
    "               'totalrevenue':'f3b01',\n",
    "               'tuitionrevenue':'f3d01'}\n",
    "\n",
    "public02 = {'totalexpense':'f1c151',\n",
    "            'instructionexpense':'f1c011',\n",
    "            'totalrevenue':'f1b09',\n",
    "            'tuitionrevenue':'f1b01'}\n",
    "\n",
    "public10 = {'totalexpense':'f1c191',\n",
    "            'instructionexpense':'f1c011',\n",
    "            'totalrevenue':'f1b09',\n",
    "            'tuitionrevenue':'f1b01'}\n",
    "\n",
    "multi_by_sector = {1997:{'f9697_f1.csv':public97,\n",
    "                         'f9697_f2.csv':private97},\n",
    "                   1998:{'f9798_f1.csv':public97,\n",
    "                         'f9798_f2.csv':nonprofit98,\n",
    "                         'f9798_f3.csv':forprofit98},\n",
    "                   1999:{'f9899_f1.csv':public97,\n",
    "                         'f9899_f2.csv':nonprofit98,\n",
    "                         'f9899_f3.csv':forprofit98},\n",
    "                   2000:{'f9900_f1.csv':public97,\n",
    "                         'f9900f2.csv':nonprofit00,\n",
    "                         'f9900f3.csv':forprofit00},\n",
    "                   2001:{'f0001_f1.csv':public97,\n",
    "                         'f0001_f2.csv':nonprofit00,\n",
    "                         'f0001_f3.csv':forprofit00},\n",
    "                   2002:{'f0102_f1.csv':public97,\n",
    "                         'f0102_f1a.csv':public02,\n",
    "                         'f0102_f2.csv':nonprofit00,\n",
    "                         'f0102_f3.csv':forprofit00},\n",
    "                   2003:{'f0203_f1.csv':public97,\n",
    "                         'f0203_f1a.csv':public02,\n",
    "                         'f0203_f2.csv':nonprofit00,\n",
    "                         'f0203_f3.csv':forprofit00},\n",
    "                   2004:{'f0304_f1a.csv':public02,\n",
    "                         'f0304_f2.csv':nonprofit00,\n",
    "                         'f0304_f3.csv':forprofit00},\n",
    "                   2005:{'f0405_f1a.csv':public02,\n",
    "                         'f0405_f2.csv':nonprofit00,\n",
    "                         'f0405_f3.csv':forprofit00},\n",
    "                   2006:{'f0506_f1a.csv':public02,\n",
    "                         'f0506_f2.csv':nonprofit00,\n",
    "                         'f0506_f3.csv':forprofit00},\n",
    "                   2007:{'f0607_f1a.csv':public02,\n",
    "                         'f0607_f2.csv':nonprofit00,\n",
    "                         'f0607_f3.csv':forprofit00},\n",
    "                   2008:{'f0708_f1a.csv':public02,\n",
    "                         'f0708_f2.csv':nonprofit00,\n",
    "                         'f0708_f3.csv':forprofit00},\n",
    "                   2009:{'f0809_f1a.csv':public02,\n",
    "                         'f0809_f2.csv':nonprofit00,\n",
    "                         'f0809_f3.csv':forprofit00},\n",
    "                   2010:{'f0910_f1a.csv':public10,\n",
    "                         'f0910_f2.csv':nonprofit00,\n",
    "                         'f0910_f3.csv':forprofit00},\n",
    "                   2011:{'f1011_f1a.csv':public10,\n",
    "                         'f1011_f2.csv':nonprofit00,\n",
    "                         'f1011_f3.csv':forprofit00},\n",
    "                   2012:{'f1112_f1a.csv':public10,\n",
    "                         'f1112_f2.csv':nonprofit00,\n",
    "                         'f1112_f3.csv':forprofit00},\n",
    "                   2013:{'f1213_f1a.csv':public10,\n",
    "                         'f1213_f2.csv':nonprofit00,\n",
    "                         'f1213_f3.csv':forprofit00}}\n",
    "\n",
    "\n",
    "def process_multi_sector_financial(csvdict):\n",
    "    dfs_to_merge = []\n",
    "    for csvfile, mapping in csvdict.items():\n",
    "        dfs_to_merge.append(process_single_financial(\"../data/\" + csvfile, mapping))\n",
    "    merged = pd.concat(dfs_to_merge)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, cvsdict in multi_by_sector.items():\n",
    "    financedfs[year] = process_multi_sector_financial(cvsdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, yeardf in dataframes.items():\n",
    "    dataframes[year] = pd.merge(yeardf, financedfs[year], how='left', left_index=True, right_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
