{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and combining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "datadir = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk through the process of cleaning and combining the data from IPEDS into a data set for analysis. The final form at the end will be a pandas panel (appropriately serialized and stored) which contains the following information:\n",
    "\n",
    "* for each year between 1984 and 2013 (the items axis)\n",
    "    * for each institution (the major axis)\n",
    "        * institutional characteristics:\n",
    "            1. The IPEDS unit ID\n",
    "            2. the institution name\n",
    "            3. the sector (public/private; for profit/nonprofit; less than 2 year/2 year/4+ year)\n",
    "            4. latitude and longitude (for mapping purposes)\n",
    "        * Fall Enrollments:\n",
    "            1. Undergraduate FTE\n",
    "            2. Ethnicities will go here if I decide I need them\n",
    "            3. Incoming test scores will go here if I can find them (I've seen them for later years, but not for earlier years)\n",
    "        * Faculty and staff characteristics:\n",
    "            1. number of faculty in each academic rank\n",
    "            2. median salaries\n",
    "            3. percentages with terminal degrees\n",
    "            4. size of administrative staff\n",
    "            5. non-faculty staff salary information (by job type? or something?)\n",
    "        * Finances\n",
    "            1. size of the endowment (mostly for private, non-profit institutions)\n",
    "            2. tuition revenues\n",
    "            3. State and Federal appropriations/grants\n",
    "            4. research revenues\n",
    "            5. instructional costs\n",
    "            6. other costs\n",
    "        * Admissions\n",
    "            1. Number of applicants\n",
    "            2. Number of admits\n",
    "            3. number of enrollees\n",
    "        * Retention\n",
    "            1. First year retention\n",
    "            2. other retention numbers, if available\n",
    "            3. 4 year completion rate\n",
    "            4. 6 year completion rate\n",
    "        * Tuition, financial aid and student debt\n",
    "            1. sticker price (tuition only)\n",
    "            2. fully loaded cost\n",
    "            3. discount rate\n",
    "            4. percentage of students receiving aid\n",
    "            5. average award amount\n",
    "            6. average student debt\n",
    "\n",
    "That's an impressively long list. The variables are spread across several files (and different files for different years). We'll do each category separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Institutional Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(csvfile, columns, charcols):\n",
    "    raw = pd.read_csv(datadir + csvfile, encoding='latin-1')\n",
    "    # standardize column names to uppercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    \n",
    "    # only transform the columns if we actually have them\n",
    "    # they may not be present in every year\n",
    "    intersect = list(set(charcols) & set(prepped.columns))\n",
    "    for col in intersect:\n",
    "        prepped[col] = prepped[col].str.strip()\n",
    "    \n",
    "    cooked = pd.DataFrame(prepped, columns=columns)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (6,214) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (41,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (92,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n"
     ]
    }
   ],
   "source": [
    "# the variables we want\n",
    "columns = ['instnm', 'sector', 'act', 'latitude', 'longitud']\n",
    "\n",
    "# these columns have string values; we want to trim extra whitespace.\n",
    "charcols = ['instnm', 'act']\n",
    "\n",
    "# files for institutional characteristics\n",
    "csvfiles = {1984: 'ic1984.csv',\n",
    "            1985: 'ic1985.csv',\n",
    "            1986: 'ic1986_a.csv',\n",
    "            1987: 'ic1987_a.csv',\n",
    "            1988: 'ic1988_a.csv',\n",
    "            1989: 'ic1989_a.csv',\n",
    "            1990: 'ic90hd.csv',\n",
    "            1991: 'ic1991_hdr.csv',\n",
    "            1992: 'ic1992_a.csv',\n",
    "            1993: 'ic1993_a.csv',\n",
    "            1994: 'ic1994_a.csv',\n",
    "            1995: 'ic9596_a.csv',\n",
    "            1996: 'ic9697_a.csv',\n",
    "            1997: 'ic9798_hdr.csv',\n",
    "            1998: 'ic98hdac.csv',\n",
    "            1999: 'ic99_hd.csv',\n",
    "            2000: 'fa2000hd.csv',\n",
    "            2001: 'fa2001hd.csv',\n",
    "            2002: 'hd2002.csv',\n",
    "            2003: 'hd2003.csv',\n",
    "            2004: 'hd2004.csv',\n",
    "            2005: 'hd2005.csv',\n",
    "            2006: 'hd2006.csv',\n",
    "            2007: 'hd2007.csv',\n",
    "            2008: 'hd2008.csv',\n",
    "            2009: 'hd2009.csv',\n",
    "            2010: 'hd2010.csv',\n",
    "            2011: 'hd2011.csv',\n",
    "            2012: 'hd2012.csv',\n",
    "            2013: 'hd2013.csv'}\n",
    "\n",
    "dataframes = {}\n",
    "for year in csvfiles.keys():\n",
    "    dataframes[year] = process(csvfiles[year], columns, charcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix 1986\n",
    "\n",
    "In 1986, more than 1200 institutions were added to IPEDS, and got the same unitid in the institutional characteristics file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[247719]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[1986].index.get_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sector</th>\n",
       "      <th>act</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sector  act  latitude  longitud\n",
       "count    1264    0         0         0\n",
       "mean        9  NaN       NaN       NaN\n",
       "std         0  NaN       NaN       NaN\n",
       "min         9  NaN       NaN       NaN\n",
       "25%         9  NaN       NaN       NaN\n",
       "50%         9  NaN       NaN       NaN\n",
       "75%         9  NaN       NaN       NaN\n",
       "max         9  NaN       NaN       NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[1986].ix[247719].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since they're all sector 9 institutions (which I don't care about too much) the easiest thing is to just drop them from 1986. The ones that show up in later years with correct unitids will continue on from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this would work in pandas 0.17, but unfortunately I'm running 0.16.\n",
    "#dataframes[1986] = dataframes[1986].reset_index().drop_duplicates(subset='index', keep=False).set_index('index')\n",
    "\n",
    "dataframes[1986] = dataframes[1986].reset_index().drop_duplicates(subset='unitid').set_index('unitid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[1986].index.get_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with NaNs\n",
    "\n",
    "The columns listing activity, latitude, and longitude are relatively late additions to the data. Activity first appears in 1998, and the location data shows up in 2009. For the years prior to that, I'm going to grab latitudes and longitudes from 2009, and set all of the activities prior to 1998 to 'A', which means 'active'.\n",
    "\n",
    "In addition to that, the sector designation didn't appear before 1986, and even in 86 and 87 there were a few with undefined sectors. We'll drop those, and copy the sectors from 1986 back to 1984 and 1985.\n",
    "\n",
    "#### Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframes[1984]['sector'] = dataframes[1986]['sector']\n",
    "dataframes[1985]['sector'] = dataframes[1986]['sector']\n",
    "\n",
    "for year in [1984, 1985, 1986, 1987]:\n",
    "    dataframes[year] = dataframes[year].dropna(subset=['sector'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year in range(1984, 1998):\n",
    "    dataframes[year]['act'] = 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lat/Lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year in range(1984, 2009):\n",
    "    dataframes[year]['latitude'] = dataframes[2009]['latitude']\n",
    "    dataframes[year]['longitud'] = dataframes[2009]['longitud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sector</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3471.000000</td>\n",
       "      <td>2991.000000</td>\n",
       "      <td>2991.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.691731</td>\n",
       "      <td>38.237865</td>\n",
       "      <td>-89.048261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.513641</td>\n",
       "      <td>5.468945</td>\n",
       "      <td>18.560790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-14.322592</td>\n",
       "      <td>-170.742769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>35.006035</td>\n",
       "      <td>-96.071824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.510445</td>\n",
       "      <td>-85.505540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>41.798333</td>\n",
       "      <td>-77.240769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>64.858048</td>\n",
       "      <td>158.212434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sector     latitude     longitud\n",
       "count  3471.000000  2991.000000  2991.000000\n",
       "mean      2.691731    38.237865   -89.048261\n",
       "std       1.513641     5.468945    18.560790\n",
       "min       0.000000   -14.322592  -170.742769\n",
       "25%       2.000000    35.006035   -96.071824\n",
       "50%       2.000000    39.510445   -85.505540\n",
       "75%       4.000000    41.798333   -77.240769\n",
       "max       9.000000    64.858048   158.212434"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[1984].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have some NaNs, but they're tremendously reduced.\n",
    "\n",
    "### Subset on Sector\n",
    "\n",
    "I'm focusing on 4-year, degree granting institutions in this study, so I'm only going to grab the institutions in the approprate sectors (1, 2, and 3). Two-year schools are sectors 4, 5, and 6, and less than 2-year schools are 7, 8, and 9. People interested in looking at those sorts of instiution could easily modify this section to pull out the appropriate data. \n",
    "\n",
    "We will do all of the merges below as left joins, so this effectively limits what goes into our final data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for year, df in dataframes.items():\n",
    "    dataframes[year] = df[(df['sector']>0) & (df['sector']<4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fall enrollments\n",
    "\n",
    "Unfortunately, what is reported in this section and how it is reported have changed significantly over the 30 year period we're studying. Some distinctions, like age categories, were added, and others, like the year in school, have been removed. Breakdown by ethnicity is available most years, but not all (*e.g.*, 1985).\n",
    "\n",
    "I'll keep things relatively simple and look at full-time undergraduate men, full-time undergraduate women, part-time undergraduate men, part-time undergraduate women, and grand total of all students. The data is reported as long form panel data, so we'll have to do some grouping to extract the pieces we want into columns for a single unitid.\n",
    "\n",
    "A little modification to our process routine will allow for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process(csvfile, columns, charcols=[], groupcolumn=None,\n",
    "            grouplabels=None, collabels=None):\n",
    "    raw = pd.read_csv(datadir + csvfile, encoding='latin-1')\n",
    "    # standardize column names to uppercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "\n",
    "    if groupcolumn is not None:\n",
    "        if grouplabels is None or collabels is None:\n",
    "            raise KeyError('Specify labels for the desired groups and columns.')\n",
    "        grouped = prepped.groupby(groupcolumn)\n",
    "        merged = None\n",
    "        for value, label in grouplabels:\n",
    "            groupedcols = {}\n",
    "            for key, val in collabels.items():\n",
    "                groupedcols[key] = label + val\n",
    "            if merged is None:\n",
    "                merged = pd.DataFrame(grouped.get_group(value), columns=groupedcols.keys())\n",
    "                merged.columns = groupedcols.values()\n",
    "            else:\n",
    "                labeldf = pd.DataFrame(grouped.get_group(value), columns=groupedcols.keys())\n",
    "                labeldf.columns = groupedcols.values()\n",
    "                merged = pd.merge(merged, labeldf, left_index=True, right_index=True)\n",
    "        prepped = merged\n",
    "        \n",
    "    \n",
    "    # only transform the columns if we actually have them\n",
    "    # they may not be present in every year\n",
    "    intersect = list(set(charcols) & set(prepped.columns))\n",
    "    for col in intersect:\n",
    "        prepped[col] = prepped[col].str.strip()\n",
    "    \n",
    "    cooked = pd.DataFrame(prepped, columns=columns)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to set up a dictionary to give `process` what it needs: the csv file name, the name of the column to group on, the labels and values of the groups, and a translation for the columns to extract.  I'm choosing to pass these things in rather than hardcode them for a couple of reasons. First, I think this same approach will be necessary when looking at the faculty section, and I'd prefer not to repeat myself. Second, most of these things change over the course of the data.  \n",
    "\n",
    "I'm actually able to group over the same column in every case, even though in about 2000 another, more detailed breakdown was added. Also, in 2008, the names of the columns I want to extract changed. An additional wrinkle is that up until 2008, they didn't report total students; they kept it broken out in total men and total women. After 2008, they have an additional column which is the sum of the other two. Rather than try to take it if it's there, I'm just going to calculate it after the fact for every case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the variables we want to extract:\n",
    "# FTUGM : Full-time undergraduate men\n",
    "# FTUGW : Full-time undergraduate women\n",
    "# PTUGM : Part-time undergraduate men\n",
    "# PTUGW : Part-time undergraduate women\n",
    "# ALLM : Total Men (including graduate and professional students)\n",
    "# ALLW : Total Women (including graduate and professional students)\n",
    "columns = ['ftugm', 'ftugw', 'ptugm', 'ptugw', 'allm', 'allw']\n",
    "\n",
    "# No string values in this set\n",
    "charcols = []\n",
    "\n",
    "agg84 = {'groupcolumn':'line',\n",
    "         'grouplabels':((1,'ftug'), ((15,'ptug')), ((29,'all'))),\n",
    "         'collabels': {'efrace15':'m', 'efrace16':'w'}}\n",
    "\n",
    "agg86 = {'groupcolumn':'line',\n",
    "         'grouplabels':((8,'ftug'), ((22,'ptug')), ((29,'all'))),\n",
    "         'collabels': {'efrace15':'m', 'efrace16':'w'}}\n",
    "\n",
    "agg08 = {'groupcolumn':'line',\n",
    "         'grouplabels':((8,'ftug'), ((22,'ptug')), ((29,'all'))),\n",
    "         'collabels': {'eftotlm':'m', 'eftotlw':'w'}}\n",
    "\n",
    "\n",
    "# files and columns for fall enrollments\n",
    "years = {1984: {'csv':'ef1984.csv',\n",
    "                'aggregation':agg84},\n",
    "         1985: {'csv':'ef1985.csv',\n",
    "                'aggregation':agg84},\n",
    "         1986: {'csv':'ef1986_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1987: {'csv':'ef1987_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1988: {'csv':'ef1988_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1989: {'csv':'ef1989_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1990: {'csv':'ef90_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1991: {'csv':'ef1991_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1992: {'csv':'ef1992_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1993: {'csv':'ef1993_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1994: {'csv':'ef1994_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1995: {'csv':'ef95_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1996: {'csv':'ef96_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1997: {'csv':'ef97_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1998: {'csv':'ef98_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1999: {'csv':'ef99_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         2000: {'csv':'ef2000a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2001: {'csv':'ef2001a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2002: {'csv':'ef2002a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2003: {'csv':'ef2003a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2004: {'csv':'ef2004a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2005: {'csv':'ef2005a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2006: {'csv':'ef2006a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2007: {'csv':'ef2007a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2008: {'csv':'ef2008a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2009: {'csv':'ef2009a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2010: {'csv':'ef2010a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2011: {'csv':'ef2011a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2012: {'csv':'ef2012a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2013: {'csv':'ef2013a.csv',\n",
    "                'aggregation':agg08},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "efdataframes = {}\n",
    "for year, info in years.items():\n",
    "    efdataframes[year] = process(info['csv'], columns, charcols,\n",
    "                                groupcolumn=info['aggregation']['groupcolumn'],\n",
    "                                grouplabels=info['aggregation']['grouplabels'],\n",
    "                                collabels=info['aggregation']['collabels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute totals and ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for enroldf in efdataframes.values():\n",
    "    # totals for full time, part time, and all students\n",
    "    enroldf['ftugt'] = enroldf['ftugm'] + enroldf['ftugw']\n",
    "    enroldf['ptugt'] = enroldf['ptugm'] + enroldf['ptugw']\n",
    "    enroldf['allt'] = enroldf['allm'] + enroldf['allw']\n",
    "    \n",
    "    # male/total fraction for FTUG:\n",
    "    enroldf['ftmf'] = enroldf['ftugm']/enroldf['ftugt']\n",
    "    \n",
    "    # FT undergraduate fraction:\n",
    "    enroldf['ugfrac'] = enroldf['ftugt']/enroldf['allt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge into existing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, yeardf in dataframes.items():\n",
    "    dataframes[year] = pd.merge(yeardf, efdataframes[year], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instnm</th>\n",
       "      <th>sector</th>\n",
       "      <th>act</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitud</th>\n",
       "      <th>ftugm</th>\n",
       "      <th>ftugw</th>\n",
       "      <th>ptugm</th>\n",
       "      <th>ptugw</th>\n",
       "      <th>allm</th>\n",
       "      <th>allw</th>\n",
       "      <th>ftugt</th>\n",
       "      <th>ptugt</th>\n",
       "      <th>allt</th>\n",
       "      <th>ftmf</th>\n",
       "      <th>ugfrac</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100654</th>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>34.783368</td>\n",
       "      <td>-86.568502</td>\n",
       "      <td>1836</td>\n",
       "      <td>1963</td>\n",
       "      <td>133</td>\n",
       "      <td>119</td>\n",
       "      <td>2268</td>\n",
       "      <td>2752</td>\n",
       "      <td>3799</td>\n",
       "      <td>252</td>\n",
       "      <td>5020</td>\n",
       "      <td>0.483285</td>\n",
       "      <td>0.756773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100663</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>33.502230</td>\n",
       "      <td>-86.809170</td>\n",
       "      <td>3501</td>\n",
       "      <td>4856</td>\n",
       "      <td>1279</td>\n",
       "      <td>1866</td>\n",
       "      <td>7309</td>\n",
       "      <td>11259</td>\n",
       "      <td>8357</td>\n",
       "      <td>3145</td>\n",
       "      <td>18568</td>\n",
       "      <td>0.418930</td>\n",
       "      <td>0.450075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100690</th>\n",
       "      <td>Amridge University</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>32.362609</td>\n",
       "      <td>-86.174010</td>\n",
       "      <td>74</td>\n",
       "      <td>128</td>\n",
       "      <td>52</td>\n",
       "      <td>68</td>\n",
       "      <td>264</td>\n",
       "      <td>367</td>\n",
       "      <td>202</td>\n",
       "      <td>120</td>\n",
       "      <td>631</td>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.320127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100706</th>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>34.722818</td>\n",
       "      <td>-86.638420</td>\n",
       "      <td>2331</td>\n",
       "      <td>1906</td>\n",
       "      <td>846</td>\n",
       "      <td>613</td>\n",
       "      <td>4136</td>\n",
       "      <td>3240</td>\n",
       "      <td>4237</td>\n",
       "      <td>1459</td>\n",
       "      <td>7376</td>\n",
       "      <td>0.550153</td>\n",
       "      <td>0.574431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100724</th>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>32.364317</td>\n",
       "      <td>-86.295677</td>\n",
       "      <td>1975</td>\n",
       "      <td>2897</td>\n",
       "      <td>213</td>\n",
       "      <td>271</td>\n",
       "      <td>2399</td>\n",
       "      <td>3676</td>\n",
       "      <td>4872</td>\n",
       "      <td>484</td>\n",
       "      <td>6075</td>\n",
       "      <td>0.405378</td>\n",
       "      <td>0.801975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     instnm  sector act   latitude   longitud  \\\n",
       "unitid                                                                          \n",
       "100654             Alabama A & M University       1   A  34.783368 -86.568502   \n",
       "100663  University of Alabama at Birmingham       1   A  33.502230 -86.809170   \n",
       "100690                   Amridge University       2   A  32.362609 -86.174010   \n",
       "100706  University of Alabama in Huntsville       1   A  34.722818 -86.638420   \n",
       "100724             Alabama State University       1   A  32.364317 -86.295677   \n",
       "\n",
       "        ftugm  ftugw  ptugm  ptugw  allm   allw  ftugt  ptugt   allt  \\\n",
       "unitid                                                                 \n",
       "100654   1836   1963    133    119  2268   2752   3799    252   5020   \n",
       "100663   3501   4856   1279   1866  7309  11259   8357   3145  18568   \n",
       "100690     74    128     52     68   264    367    202    120    631   \n",
       "100706   2331   1906    846    613  4136   3240   4237   1459   7376   \n",
       "100724   1975   2897    213    271  2399   3676   4872    484   6075   \n",
       "\n",
       "            ftmf    ugfrac  \n",
       "unitid                      \n",
       "100654  0.483285  0.756773  \n",
       "100663  0.418930  0.450075  \n",
       "100690  0.366337  0.320127  \n",
       "100706  0.550153  0.574431  \n",
       "100724  0.405378  0.801975  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[2013].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Faculty and staff\n",
    "\n",
    "IPEDS has three different surveys that deal with faculty and staff:\n",
    "* Instructional staff/Salaries.  This survey is the most complete (in terms of years of availability), but has some significant drawbacks. The 2012 and 2013 surveys have non-instructional staff included, but none of the other years do. The surveys between 2005 and 2011 include people on contracts less than 9 months (*i.e.*, adjuncts) but other years don't. Fringe benefits were included up until 2010, but apparently not after that. Furthermore, 9 and 12 month contracts are reported separately. While there may be some deeply meaningful reason for doing so, it makes things a little more difficult for me.\n",
    "* Fall Staff. Available from 1987 onward in odd years, and every year after 2001. This includes noninstructional staff in a whole host of categories, but doesn't include any salary data.\n",
    "* Employees by Assigned Position. From 2001 on. Has many more categories than either of the others. Includes tenure status but not faculty rank.\n",
    "\n",
    "If I want to cover the whole range of years (which I do), I can get closest by using the first of these, which means largely ignoring noninstructional staff and adjuncts and dealing with the 9/12 month issues.  I'll do that for a first pass, at least.\n",
    "\n",
    "The files seem to come in two flavors: wide and long. The long flavor has a variable for academic rank (and another for contract type) which we can group over.  The wide flavor just has all of the variables in a single row.\n",
    "* wide: 1987, 1989-1998 \n",
    "* long: 1984, 1985, 1999, 2001-2013 \n",
    "* missing: 1986, 1988, 2000\n",
    "\n",
    "We process the long flavor files like the fall enrolment, above.  The wide ones are easier; they're like the institutional characteristics we did first.\n",
    "\n",
    "The last thing to do before we actually process is to decide which columns we want to keep. We have two sexes, between two and four contract durations, six academic ranks (full, associate, assistant, instructor, lecturer, and no rank), and three tenure statuses (tenured, tenure track, and non-tenure track), for a total of up to 144 columns. That's clearly too many, and in fact, some of the years don't have that many.\n",
    "\n",
    "If I ignore tenure status (which isn't reported every year, anyway), and gender distribution (there are people better qualified than I to study diversity issues), and contract length, then I'm down to six categories with two variables each (number of people and salary outlay).  Monthly salary may be a more meaningful number, but I don't really care at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wide format years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wide format\n",
    "# 1987-1997\n",
    "aggregation = {'fullcount':['a4', 'a39', 'a79', 'a114'],\n",
    "               'fulloutlay':['a5', 'a40', 'a80', 'a115'],\n",
    "               'assoccount':['a9', 'a44', 'a84', 'a119'],\n",
    "               'assocoutlay':['a10', 'a45', 'a85', 'a120'],\n",
    "               'assistcount':['a14', 'a49', 'a89', 'a124'],\n",
    "               'assistoutlay':['a15', 'a50', 'a90', 'a125'],\n",
    "               'instrcount':['a19', 'a54', 'a94', 'a129'],\n",
    "               'instroutlay':['a20', 'a55', 'a95', 'a130'],\n",
    "               'lectcount':['a24', 'a59', 'a99', 'a134'],\n",
    "               'lectoutlay':['a25', 'a60', 'a100', 'a135'],\n",
    "               'norankcount':['a29', 'a64', 'a104', 'a139'],\n",
    "               'norankoutlay':['a30', 'a65', 'a105', 'a140']}\n",
    "\n",
    "# 1998\n",
    "agg98 = {'fullcount':['saa014', 'saa084', 'saa164', 'saa234'],\n",
    "         'fulloutlay':['saa015', 'saa085', 'saa165', 'saa235'],\n",
    "         'assoccount':['saa024', 'saa094', 'saa174', 'saa244'],\n",
    "         'assocoutlay':['saa025', 'saa095', 'saa175', 'saa245'],\n",
    "         'assistcount':['saa034', 'saa104', 'saa184', 'saa254'],\n",
    "         'assistoutlay':['saa035', 'saa105', 'saa185', 'saa255'],\n",
    "         'instrcount':['saa044', 'saa114', 'saa194', 'saa264'],\n",
    "         'instroutlay':['saa045', 'saa115', 'saa195', 'saa265'],\n",
    "         'lectcount':['saa054', 'saa124', 'saa204', 'saa274'],\n",
    "         'lectoutlay':['saa055', 'saa125', 'saa205', 'saa275'],\n",
    "         'norankcount':['saa064', 'saa134', 'saa214', 'saa284'],\n",
    "         'norankoutlay':['saa065', 'saa135', 'saa215', 'saa285']}\n",
    "\n",
    "wideyears = {1987: {'csv':'sal1987_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1989: {'csv':'sal1989_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1990: {'csv':'sal90_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1991: {'csv':'sal1991_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1992: {'csv':'sal1992_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1993: {'csv':'sal1993_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1994: {'csv':'sal1994_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1995: {'csv':'sal95_a_1.csv',\n",
    "                   'agg':aggregation},\n",
    "             1996: {'csv':'sal96_a_1.csv',\n",
    "                   'agg':aggregation},\n",
    "             1997: {'csv':'sal97_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1998: {'csv':'sal98_a.csv',\n",
    "                   'agg':agg98}}\n",
    "\n",
    "def process_wide(csvfile, aggregation):\n",
    "    raw = pd.read_csv(datadir + csvfile, encoding='latin-1')\n",
    "    # standardize column names to lowercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    \n",
    "    for aggregated, aggcols in aggregation.items():\n",
    "        prepped[aggregated] = prepped[aggcols].sum(axis=1)\n",
    "    \n",
    "    cooked = pd.DataFrame(prepped, columns=aggregation.keys()).fillna(0)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facultydfs = {}\n",
    "for year, yeardict in wideyears.items():\n",
    "    facultydfs[year] = process_wide(yeardict['csv'], yeardict['agg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create empty data frames for missing years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missingyears = [1986, 1988, 2000]\n",
    "for year in missingyears:\n",
    "    facultydfs[year] = pd.DataFrame(columns=aggregation.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do the long format years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg84 = {'count':['saa1', 'saa4'],\n",
    "         'outlay':['saa2', 'saa5'],\n",
    "         'group':'line',\n",
    "         'vals':{'full':[1,8],\n",
    "                 'assoc':[2,9],\n",
    "                 'assist':[3,10],\n",
    "                 'instr':[4,11],\n",
    "                 'lect':[5,12],\n",
    "                 'norank':[6,13]}}\n",
    "\n",
    "# in 1999, the survey separated academic rank and contract length into \n",
    "# two line items\n",
    "agg99 = {'count':['empcntm', 'empcntw'],\n",
    "         'outlay':['outlaym', 'outlayw'],\n",
    "         'group':['contract','arank'],\n",
    "         'vals':{'full':[(1,1), (2,1)],\n",
    "                 'assoc':[(1,2), (2,2)],\n",
    "                 'assist':[(1,3), (2,3)],\n",
    "                 'instr':[(1,4), (2,4)],\n",
    "                 'lect':[(1,5), (2,5)],\n",
    "                 'norank':[(1,6), (2,6)]}}\n",
    "\n",
    "# the only survey available from 2001 is a summary, which doesn't separate women and men.\n",
    "# otherwise, it's the same as 99.\n",
    "agg01 = {'count':['empcount',],\n",
    "         'outlay':['outlays',],\n",
    "         'group':['contract','arank'],\n",
    "         'vals':{'full':[(1,1), (2,1)],\n",
    "                 'assoc':[(1,2), (2,2)],\n",
    "                 'assist':[(1,3), (2,3)],\n",
    "                 'instr':[(1,4), (2,4)],\n",
    "                 'lect':[(1,5), (2,5)],\n",
    "                 'norank':[(1,6), (2,6)]}}\n",
    "\n",
    "# in 2012, the contract length went wide while the academic rank stayed long.\n",
    "# also, contract length was split into four categories instead of two.\n",
    "# fortunately, they also include an aggregated column.\n",
    "agg12 = {'count':['satotlt',],\n",
    "         'outlay':['saoutlt',],\n",
    "         'group':'arank',\n",
    "         'vals':{'full':[1,],\n",
    "                 'assoc':[2,],\n",
    "                 'assist':[3,],\n",
    "                 'instr':[4,],\n",
    "                 'lect':[5,],\n",
    "                 'norank':[6,]}}\n",
    "\n",
    "# long format\n",
    "longyears = {1984:{'csv':'sal1984_a.csv',\n",
    "                   'agg':agg84},\n",
    "             1985:{'csv':'sal1985_a.csv',\n",
    "                   'agg':agg84},\n",
    "             1999:{'csv':'sal1999_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2001:{'csv':'sal2001_a_s.csv',\n",
    "                   'agg':agg01},\n",
    "             2002:{'csv':'sal2002_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2003:{'csv':'sal2003_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2004:{'csv':'sal2004_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2005:{'csv':'sal2005_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2006:{'csv':'sal2006_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2007:{'csv':'sal2007_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2008:{'csv':'sal2008_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2009:{'csv':'sal2009_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2010:{'csv':'sal2010_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2011:{'csv':'sal2011_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2012:{'csv':'sal2012_is.csv',\n",
    "                   'agg':agg12},\n",
    "             2013:{'csv':'sal2013_is.csv',\n",
    "                   'agg':agg12}}\n",
    "\n",
    "\n",
    "def process_long(csvfile, aggregation):\n",
    "    raw = pd.read_csv(datadir + csvfile, encoding='latin-1')\n",
    "    # standardize column names to lowercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    \n",
    "    grouped = prepped.groupby(aggregation['group'])\n",
    "    collected = {}\n",
    "    for rank,val in aggregation['vals'].items():\n",
    "        groups = []\n",
    "        for subgroup in val:\n",
    "            groups.append(grouped.get_group(subgroup))\n",
    "            \n",
    "        catted = pd.concat(groups)\n",
    "        unitgroups = catted.groupby(level=0)\n",
    "        collected[rank+\"count\"] = unitgroups.sum()[aggregation['count']].sum(axis=1)\n",
    "        collected[rank+\"outlay\"] = unitgroups.sum()[aggregation['outlay']].sum(axis=1)\n",
    "        \n",
    "    cooked = pd.DataFrame(collected).fillna(0)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, yeardict in longyears.items():\n",
    "    facultydfs[year] = process_long(yeardict['csv'], yeardict['agg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Totals and ratios\n",
    "\n",
    "I want the total number of faculty, and the student/faculty ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allcounts = ['fullcount', 'assoccount', 'assistcount', 'instrcount', 'lectcount', 'norankcount']\n",
    "\n",
    "for year, facdf in facultydfs.items():\n",
    "    facdf['totalfac'] = facdf[allcounts].sum(axis=1)\n",
    "    facdf['studfacratio'] = dataframes[year]['allt']/facdf['totalfac']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge into existing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for year, yeardf in dataframes.items():\n",
    "    dataframes[year] = pd.merge(yeardf, facultydfs[year], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finances\n",
    "\n",
    "This is a complicated topic, and I am by no means an expert.  As I see it, there are four important categories of numbers in this section:\n",
    "1. income\n",
    "2. expenses\n",
    "3. assets\n",
    "4. liabilities\n",
    "\n",
    "Unfortunately, the three major types of institution (public, non-profit private, and for-profit private) have significantly different sources of income, and often very different collections of assets and liabilities, as well.  That makes comparisons difficult.  From about 1997 on the three categories of institution have their data in separate files. Before that, the organization of the data is kind of a mess. The first couple years of our range drop everything into a single file, but through most of the 90's, there are a wide array of different files for each year.\n",
    "\n",
    "I'm going to have to select a subset of the possible variables so that I don't drown in them. (There are about 200 different variables for nonprofit institutions in the 2013 data; public institutions (160) and for-profit institutions (40) have fewer). For now, I will focus on six numbers: totals for income, expenses, and debt; amount of income from tuition and fees, value of the endowment at the end of the year, and the amount expended on instructional costs.\n",
    "\n",
    "Assets are kind of a sticky area. Things like land and physical plant are very illiquid, and depend strongly on local market values. On the other hand, for-profit institutions don't have an endowment, as such, but I care less about their finances at this point. If I decide I need some other measure of total assets, or something additional for the for-profit institutions, I'll go back and refactor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping84 = {'totalrevenue':'a20', \n",
    "             'tuitionrevenue':'a01',\n",
    "             'instructionexpense':'b01',\n",
    "             'totalexpense':'b19',\n",
    "             'debt':'d04',\n",
    "             'endowment':'f64'}\n",
    "\n",
    "# total debt and endowment don't seem to be reported in 88.\n",
    "mapping88 = {'totalrevenue':'a163', \n",
    "             'tuitionrevenue':'a013',\n",
    "             'instructionexpense':'b013',\n",
    "             'totalexpense':'b223'}\n",
    "\n",
    "single_files = {1984:{'csv':'f1984.csv',\n",
    "                     'mapping':mapping84},\n",
    "               1985:{'csv':'f1985.csv',\n",
    "                     'mapping':mapping84},\n",
    "               1986:{'csv':'f1986.csv',\n",
    "                     'mapping':mapping84},\n",
    "               1988:{'csv':'f1988.csv',\n",
    "                     'mapping':mapping88}}\n",
    "\n",
    "def process_single_financial(csvfile, mapping):\n",
    "    # index col is needed for 1997, for reasons I don't fully understand\n",
    "    raw = pd.read_csv(datadir + csvfile, encoding='latin-1', index_col=False)\n",
    "    # standardize column names to uppercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    for key, colname in mapping.items():\n",
    "        prepped[key] = prepped[colname]\n",
    "    cooked = pd.DataFrame(prepped, columns=mapping.keys())\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "financedfs = {}\n",
    "for fyear, mapping in single_files.items():\n",
    "    financedfs[fyear] = process_single_financial(mapping['csv'], mapping['mapping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expenses87 = {'totalexpense':'b223',\n",
    "              'instructionexpense':'b013'}\n",
    "income87 = {'totalrevenue':'a163',\n",
    "            'tuitionrevenue':'a013'}\n",
    "debt89 = {'debt':'g041'}\n",
    "endowment89 = {'endowment':'h021'}\n",
    "\n",
    "debt93 = {'debt':'g04'}\n",
    "\n",
    "multi_by_category = {1987:{'f1987_a.csv':income87,\n",
    "                           'f1987_b.csv':expenses87},\n",
    "                     1989:{'f1989_a.csv':income87,\n",
    "                           'f1989_b.csv':expenses87,\n",
    "                           'f1989_g.csv':debt89,\n",
    "                           'f1989_h.csv':endowment89},\n",
    "                     1990:{'f8990_a.csv':income87,\n",
    "                           'f8990_b.csv':expenses87},\n",
    "                     1991:{'f1991_a.csv':income87,\n",
    "                           'f1991_b.csv':expenses87,\n",
    "                           'f1991_g.csv':debt89,\n",
    "                           'f1991_h.csv':endowment89},\n",
    "                     1992:{'f1992_a.csv':income87,\n",
    "                           'f1992_b.csv':expenses87,\n",
    "                           'f1992_g.csv':debt89,\n",
    "                           'f1992_h.csv':endowment89},\n",
    "                     1993:{'f1993_a.csv':income87,\n",
    "                           'f1993_b.csv':expenses87,\n",
    "                           'f1993_g.csv':debt93,\n",
    "                           'f1993_h.csv':endowment89},\n",
    "                     1994:{'f1994_a.csv':income87,\n",
    "                           'f1994_b.csv':expenses87,\n",
    "                           'f1994_g.csv':debt93,\n",
    "                           'f1994_h.csv':endowment89},\n",
    "                     1995:{'f9495_a.csv':income87,\n",
    "                           'f9495_b.csv':expenses87,\n",
    "                           'f9495_g.csv':debt93,\n",
    "                           'f9495_h.csv':endowment89},\n",
    "                     1996:{'f9596_a.csv':income87,\n",
    "                           'f9596_b.csv':expenses87,\n",
    "                           'f9596_g.csv':debt93,\n",
    "                           'f9596_h.csv':endowment89}}\n",
    "\n",
    "def process_multi_cat_financial(csvdict):\n",
    "    merged = None\n",
    "    for csvfile, mapping in csvdict.items():\n",
    "        if merged is None:\n",
    "            merged = process_single_financial(csvfile, mapping)\n",
    "        else:\n",
    "            temp = process_single_financial(csvfile, mapping)\n",
    "            merged = pd.merge(merged, temp, left_index=True, right_index=True)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, cvsdict in multi_by_category.items():\n",
    "    financedfs[year] = process_multi_cat_financial(cvsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "public97 = {'totalexpense':'b223',\n",
    "            'instructionexpense':'b013',\n",
    "            'totalrevenue':'a163',\n",
    "            'tuitionrevenue':'a013',\n",
    "            'debt':'g04',\n",
    "            'endowment':'h021'}\n",
    "\n",
    "private97 = {'totalexpense':'fb12_1',\n",
    "             'instructionexpense':'fb01_1',\n",
    "             'totalrevenue':'fa17_1',\n",
    "             'tuitionrevenue':'fa01_1'}\n",
    "\n",
    "nonprofit98 = {'totalexpense':'f2b12_1',\n",
    "               'instructionexpense':'f2b01_1',\n",
    "               'totalrevenue':'f2a17_1',\n",
    "               'tuitionrevenue':'f2a01_1',\n",
    "               'endowment':'f2d05'}\n",
    "\n",
    "forprofit98 = {'totalexpense':'f3b10_1',\n",
    "               'instructionexpense':'f3b01_1',\n",
    "               'totalrevenue':'f3a10',\n",
    "               'tuitionrevenue':'f3a01'}\n",
    "\n",
    "nonprofit00 = {'totalrevenue':'f2b01',\n",
    "               'tuitionrevenue':'f2d01',\n",
    "               'totalexpense':'f2b02',\n",
    "               'instructionexpense':'f2e011',\n",
    "               'endowment':'f2a01'}\n",
    "\n",
    "forprofit00 = {'totalexpense':'f3b02',\n",
    "               'instructionexpense':'f3e01',\n",
    "               'totalrevenue':'f3b01',\n",
    "               'tuitionrevenue':'f3d01'}\n",
    "\n",
    "public02 = {'totalexpense':'f1c151',\n",
    "            'instructionexpense':'f1c011',\n",
    "            'totalrevenue':'f1b09',\n",
    "            'tuitionrevenue':'f1b01'}\n",
    "\n",
    "public10 = {'totalexpense':'f1c191',\n",
    "            'instructionexpense':'f1c011',\n",
    "            'totalrevenue':'f1b09',\n",
    "            'tuitionrevenue':'f1b01'}\n",
    "\n",
    "multi_by_sector = {1997:{'f9697_f1.csv':public97,\n",
    "                         'f9697_f2.csv':private97},\n",
    "                   1998:{'f9798_f1.csv':public97,\n",
    "                         'f9798_f2.csv':nonprofit98,\n",
    "                         'f9798_f3.csv':forprofit98},\n",
    "                   1999:{'f9899_f1.csv':public97,\n",
    "                         'f9899_f2.csv':nonprofit98,\n",
    "                         'f9899_f3.csv':forprofit98},\n",
    "                   2000:{'f9900_f1.csv':public97,\n",
    "                         'f9900f2.csv':nonprofit00,\n",
    "                         'f9900f3.csv':forprofit00},\n",
    "                   2001:{'f0001_f1.csv':public97,\n",
    "                         'f0001_f2.csv':nonprofit00,\n",
    "                         'f0001_f3.csv':forprofit00},\n",
    "                   2002:{'f0102_f1.csv':public97,\n",
    "                         'f0102_f1a.csv':public02,\n",
    "                         'f0102_f2.csv':nonprofit00,\n",
    "                         'f0102_f3.csv':forprofit00},\n",
    "                   2003:{'f0203_f1.csv':public97,\n",
    "                         'f0203_f1a.csv':public02,\n",
    "                         'f0203_f2.csv':nonprofit00,\n",
    "                         'f0203_f3.csv':forprofit00},\n",
    "                   2004:{'f0304_f1a.csv':public02,\n",
    "                         'f0304_f2.csv':nonprofit00,\n",
    "                         'f0304_f3.csv':forprofit00},\n",
    "                   2005:{'f0405_f1a.csv':public02,\n",
    "                         'f0405_f2.csv':nonprofit00,\n",
    "                         'f0405_f3.csv':forprofit00},\n",
    "                   2006:{'f0506_f1a.csv':public02,\n",
    "                         'f0506_f2.csv':nonprofit00,\n",
    "                         'f0506_f3.csv':forprofit00},\n",
    "                   2007:{'f0607_f1a.csv':public02,\n",
    "                         'f0607_f2.csv':nonprofit00,\n",
    "                         'f0607_f3.csv':forprofit00},\n",
    "                   2008:{'f0708_f1a.csv':public02,\n",
    "                         'f0708_f2.csv':nonprofit00,\n",
    "                         'f0708_f3.csv':forprofit00},\n",
    "                   2009:{'f0809_f1a.csv':public02,\n",
    "                         'f0809_f2.csv':nonprofit00,\n",
    "                         'f0809_f3.csv':forprofit00},\n",
    "                   2010:{'f0910_f1a.csv':public10,\n",
    "                         'f0910_f2.csv':nonprofit00,\n",
    "                         'f0910_f3.csv':forprofit00},\n",
    "                   2011:{'f1011_f1a.csv':public10,\n",
    "                         'f1011_f2.csv':nonprofit00,\n",
    "                         'f1011_f3.csv':forprofit00},\n",
    "                   2012:{'f1112_f1a.csv':public10,\n",
    "                         'f1112_f2.csv':nonprofit00,\n",
    "                         'f1112_f3.csv':forprofit00},\n",
    "                   2013:{'f1213_f1a.csv':public10,\n",
    "                         'f1213_f2.csv':nonprofit00,\n",
    "                         'f1213_f3.csv':forprofit00}}\n",
    "\n",
    "\n",
    "def process_multi_sector_financial(csvdict):\n",
    "    dfs_to_merge = []\n",
    "    for csvfile, mapping in csvdict.items():\n",
    "        dfs_to_merge.append(process_single_financial(csvfile, mapping))\n",
    "    merged = pd.concat(dfs_to_merge)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, cvsdict in multi_by_sector.items():\n",
    "    financedfs[year] = process_multi_sector_financial(cvsdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate some ratios\n",
    "\n",
    "There are two ratios in particular I'm interested in: the fraction of total revenue made up by tuition revenues (tuition dependence) and the fraction of total expenses made up by instruction (teaching centeredness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, df in financedfs.items():\n",
    "    try:\n",
    "        df['tuitiondependence'] = df['tuitionrevenue']/df['totalrevenue']\n",
    "    except ZeroDivisionError:\n",
    "        df['tuitiondependence'] = -1.0\n",
    "    try:\n",
    "        df['teachingcenteredness'] = df['instructionexpense']/df['totalexpense']\n",
    "    except ZeroDivisionError:\n",
    "        df['teachingcenteredness'] = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, yeardf in dataframes.items():\n",
    "    dataframes[year] = pd.merge(yeardf, financedfs[year], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tuition, financial aid, and student debt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize and Store\n",
    "\n",
    "We have a lot of options for serializing this data set. If we just want to store the data, without adding any functionality, we can use pickle, json, or even csv. Of these three, json might be the most versatile, simply because it allows more structure than csv but is more cross-language than pickle. An additional advantage to json is that if we're going to use something like D3 for visualization, the data is already packaged.\n",
    "\n",
    "Dataframes lend themselves to a SQL serialization, but we really want the third dimension in this dataset, and that doesn't seem like a natural fit for SQL. So, I'm going to go with HDF. It's fast, it handles large datasets well, and it can do some selection on the data, meaning that we don't have to retrieve everything if we're just looking at a few variables (which wouldn't be possible with json).\n",
    "\n",
    "We first have to combine the collection of dataframes into a panel, and then serialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/pytables.py:2577: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block0_values] [items->[1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013]]\n",
      "\n",
      "  warnings.warn(ws, PerformanceWarning)\n"
     ]
    }
   ],
   "source": [
    "collegestats = pd.Panel(dataframes)\n",
    "\n",
    "collegestats.to_hdf('../data/collegestats.h5', 'collegestats', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
