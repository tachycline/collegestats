{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk through the process of cleaning and combining the data from IPEDS into a data set for analysis. The final form at the end will be a pandas panel (appropriately serialized and stored) which contains the following information:\n",
    "\n",
    "* for each year between 1984 and 2013 (the items axis)\n",
    "    * for each institution (the major axis)\n",
    "        * institutional characteristics:\n",
    "            1. The IPEDS unit ID\n",
    "            2. the institution name\n",
    "            3. the sector (public/private; for profit/nonprofit; less than 2 year/2 year/4+ year)\n",
    "            4. latitude and longitude (for mapping purposes)\n",
    "        * Fall Enrollments:\n",
    "            1. Undergraduate FTE\n",
    "            2. Ethnicities will go here if I decide I need them\n",
    "            3. Incoming test scores will go here if I can find them (I've seen them for later years, but not for earlier years)\n",
    "        * Faculty and staff characteristics:\n",
    "            1. number of faculty in each academic rank\n",
    "            2. median salaries\n",
    "            3. percentages with terminal degrees\n",
    "            4. size of administrative staff\n",
    "            5. non-faculty staff salary information (by job type? or something?)\n",
    "        * Finances\n",
    "            1. size of the endowment (mostly for private, non-profit institutions)\n",
    "            2. tuition revenues\n",
    "            3. State and Federal appropriations/grants\n",
    "            4. research revenues\n",
    "            5. instructional costs\n",
    "            6. other costs\n",
    "        * Admissions\n",
    "            1. Number of applicants\n",
    "            2. Number of admits\n",
    "            3. number of enrollees\n",
    "        * Retention\n",
    "            1. First year retention\n",
    "            2. other retention numbers, if available\n",
    "            3. 4 year completion rate\n",
    "            4. 6 year completion rate\n",
    "        * Tuition, financial aid and student debt\n",
    "            1. sticker price (tution only)\n",
    "            2. fully loaded cost\n",
    "            3. discount rate\n",
    "            4. percentage of students receiving aid\n",
    "            5. average award amount\n",
    "            6. average student debt\n",
    "\n",
    "That's an impressively long list. The variables are spread across several files (and different files for different years). We'll do each category separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Institutional Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(csvfile, columns, charcols):\n",
    "    raw = pd.read_csv(csvfile, encoding='latin-1')\n",
    "    # standardize column names to uppercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    \n",
    "    # only transform the columns if we actually have them\n",
    "    # they may not be present in every year\n",
    "    intersect = list(set(charcols) & set(prepped.columns))\n",
    "    for col in intersect:\n",
    "        prepped[col] = prepped[col].str.strip()\n",
    "    \n",
    "    cooked = pd.DataFrame(prepped, columns=columns)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (6,214) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (41,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (92,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n",
      "/Users/cmckay/anaconda/envs/collegestats/lib/python3.4/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n"
     ]
    }
   ],
   "source": [
    "# the variables we want\n",
    "columns = ['instnm', 'sector', 'act', 'latitude', 'longitud']\n",
    "\n",
    "# these columns have string values; we want to trim extra whitespace.\n",
    "charcols = ['instnm', 'act']\n",
    "\n",
    "# files for institutional characteristics\n",
    "csvfiles = {1984: 'ic1984.csv',\n",
    "            1985: 'ic1985.csv',\n",
    "            1986: 'ic1986_a.csv',\n",
    "            1987: 'ic1987_a.csv',\n",
    "            1988: 'ic1988_a.csv',\n",
    "            1989: 'ic1989_a.csv',\n",
    "            1990: 'ic90hd.csv',\n",
    "            1991: 'ic1991_hdr.csv',\n",
    "            1992: 'ic1992_a.csv',\n",
    "            1993: 'ic1993_a.csv',\n",
    "            1994: 'ic1994_a.csv',\n",
    "            1995: 'ic9596_a.csv',\n",
    "            1996: 'ic9697_a.csv',\n",
    "            1997: 'ic9798_hdr.csv',\n",
    "            1998: 'ic98hdac.csv',\n",
    "            1999: 'ic99_hd.csv',\n",
    "            2000: 'fa2000hd.csv',\n",
    "            2001: 'fa2001hd.csv',\n",
    "            2002: 'hd2002.csv',\n",
    "            2003: 'hd2003.csv',\n",
    "            2004: 'hd2004.csv',\n",
    "            2005: 'hd2005.csv',\n",
    "            2006: 'hd2006.csv',\n",
    "            2007: 'hd2007.csv',\n",
    "            2008: 'hd2008.csv',\n",
    "            2009: 'hd2009.csv',\n",
    "            2010: 'hd2010.csv',\n",
    "            2011: 'hd2011.csv',\n",
    "            2012: 'hd2012.csv',\n",
    "            2013: 'hd2013.csv'}\n",
    "\n",
    "dataframes = {}\n",
    "for year in csvfiles.keys():\n",
    "    dataframes[year] = process('../data/' + csvfiles[year], columns, charcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fall enrollments\n",
    "\n",
    "Unfortunately, what is reported in this section and how it is reported have changed significantly over the 30 year period we're studying. Some distinctions, like age categories, were added, and others, like the year in school, have been removed. Breakdown by ethnicity is available most years, but not all (*e.g.*, 1985).\n",
    "\n",
    "I'll keep things relatively simple and look at full-time undergraduate men, full-time undergraduate women, part-time undergraduate men, part-time undergraduate women, and grand total of all students. The data is reported as long form panel data, so we'll have to do some grouping to extract the pieces we want into columns for a single unitid.\n",
    "\n",
    "A little modification to our process routine will allow for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process(csvfile, columns, charcols=[], groupcolumn=None,\n",
    "            grouplabels=None, collabels=None):\n",
    "    raw = pd.read_csv(csvfile, encoding='latin-1')\n",
    "    # standardize column names to uppercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "\n",
    "    if groupcolumn is not None:\n",
    "        if grouplabels is None or collabels is None:\n",
    "            raise KeyError('Specify labels for the desired groups and columns.')\n",
    "        grouped = prepped.groupby(groupcolumn)\n",
    "        merged = None\n",
    "        for value, label in grouplabels:\n",
    "            groupedcols = {}\n",
    "            for key, val in collabels.items():\n",
    "                groupedcols[key] = label + val\n",
    "            if merged is None:\n",
    "                merged = pd.DataFrame(grouped.get_group(value), columns=groupedcols.keys())\n",
    "                merged.columns = groupedcols.values()\n",
    "            else:\n",
    "                labeldf = pd.DataFrame(grouped.get_group(value), columns=groupedcols.keys())\n",
    "                labeldf.columns = groupedcols.values()\n",
    "                merged = pd.merge(merged, labeldf, left_index=True, right_index=True)\n",
    "        prepped = merged\n",
    "        \n",
    "    \n",
    "    # only transform the columns if we actually have them\n",
    "    # they may not be present in every year\n",
    "    intersect = list(set(charcols) & set(prepped.columns))\n",
    "    for col in intersect:\n",
    "        prepped[col] = prepped[col].str.strip()\n",
    "    \n",
    "    cooked = pd.DataFrame(prepped, columns=columns)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to set up a dictionary to give `process` what it needs: the csv file name, the name of the column to group on, the labels and values of the groups, and a translation for the columns to extract.  I'm choosing to pass these things in rather than hardcode them for a couple of reasons. First, I think this same approach will be necessary when looking at the faculty section, and I'd prefer not to repeat myself. Second, most of these things change over the course of the data.  \n",
    "\n",
    "I'm actually able to group over the same column in every case, even though in about 2000 another, more detailed breakdown was added. Also, in 2008, the names of the columns I want to extract changed. An additional wrinkle is that up until 2008, they didn't report total students; they kept it broken out in total men and total women. After 2008, they have an additional column which is the sum of the other two. Rather than try to take it if it's there, I'm just going to calculate it after the fact for every case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the variables we want to extract:\n",
    "# FTUGM : Full-time undergraduate men\n",
    "# FTUGW : Full-time undergraduate women\n",
    "# PTUGM : Part-time undergraduate men\n",
    "# PTUGW : Part-time undergraduate women\n",
    "# ALLM : Total Men (including graduate and professional students)\n",
    "# ALLW : Total Women (including graduate and professional students)\n",
    "columns = ['ftugm', 'ftugw', 'ptugm', 'ptugw', 'allm', 'allw']\n",
    "\n",
    "# No string values in this set\n",
    "charcols = []\n",
    "\n",
    "agg84 = {'groupcolumn':'line',\n",
    "         'grouplabels':((1,'ftug'), ((15,'ptug')), ((29,'all'))),\n",
    "         'collabels': {'efrace15':'m', 'efrace16':'w'}}\n",
    "\n",
    "agg86 = {'groupcolumn':'line',\n",
    "         'grouplabels':((8,'ftug'), ((22,'ptug')), ((29,'all'))),\n",
    "         'collabels': {'efrace15':'m', 'efrace16':'w'}}\n",
    "\n",
    "agg08 = {'groupcolumn':'line',\n",
    "         'grouplabels':((8,'ftug'), ((22,'ptug')), ((29,'all'))),\n",
    "         'collabels': {'eftotlm':'m', 'eftotlw':'w'}}\n",
    "\n",
    "\n",
    "# files and columns for fall enrollments\n",
    "years = {1984: {'csv':'ef1984.csv',\n",
    "                'aggregation':agg84},\n",
    "         1985: {'csv':'ef1985.csv',\n",
    "                'aggregation':agg84},\n",
    "         1986: {'csv':'ef1986_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1987: {'csv':'ef1987_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1988: {'csv':'ef1988_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1989: {'csv':'ef1989_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1990: {'csv':'ef90_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1991: {'csv':'ef1991_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1992: {'csv':'ef1992_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1993: {'csv':'ef1993_a.csv',\n",
    "                'aggregation':agg86},\n",
    "         1994: {'csv':'ef1994_acp.csv',\n",
    "                'aggregation':agg86},\n",
    "         1995: {'csv':'ef95_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1996: {'csv':'ef96_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1997: {'csv':'ef97_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1998: {'csv':'ef98_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         1999: {'csv':'ef99_anr.csv',\n",
    "                'aggregation':agg86},\n",
    "         2000: {'csv':'ef2000a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2001: {'csv':'ef2001a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2002: {'csv':'ef2002a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2003: {'csv':'ef2003a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2004: {'csv':'ef2004a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2005: {'csv':'ef2005a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2006: {'csv':'ef2006a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2007: {'csv':'ef2007a.csv',\n",
    "                'aggregation':agg86},\n",
    "         2008: {'csv':'ef2008a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2009: {'csv':'ef2009a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2010: {'csv':'ef2010a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2011: {'csv':'ef2011a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2012: {'csv':'ef2012a.csv',\n",
    "                'aggregation':agg08},\n",
    "         2013: {'csv':'ef2013a.csv',\n",
    "                'aggregation':agg08},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That actually turned out to be more repeated effort than I thought it would, but I didn't realize that until I was already almost done, so I decided to keep it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "efdataframes = {}\n",
    "for year, info in years.items():\n",
    "    efdataframes[year] = process('../data/' + info['csv'], columns, charcols,\n",
    "                                groupcolumn=info['aggregation']['groupcolumn'],\n",
    "                                grouplabels=info['aggregation']['grouplabels'],\n",
    "                                collabels=info['aggregation']['collabels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute totals and ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for enroldf in efdataframes.values():\n",
    "    # totals for full time, part time, and all students\n",
    "    enroldf['ftugt'] = enroldf['ftugm'] + enroldf['ftugw']\n",
    "    enroldf['ptugt'] = enroldf['ptugm'] + enroldf['ptugw']\n",
    "    enroldf['allt'] = enroldf['allm'] + enroldf['allw']\n",
    "    \n",
    "    # male/total fraction for FTUG:\n",
    "    enroldf['ftmf'] = enroldf['ftugm']/enroldf['ftugt']\n",
    "    \n",
    "    # FT undergraduate fraction:\n",
    "    enroldf['ugfrac'] = enroldf['ftugt']/enroldf['allt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge into existing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, yeardf in dataframes.items():\n",
    "    dataframes[year] = pd.merge(yeardf, efdataframes[year], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instnm</th>\n",
       "      <th>sector</th>\n",
       "      <th>act</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitud</th>\n",
       "      <th>ftugm</th>\n",
       "      <th>ftugw</th>\n",
       "      <th>ptugm</th>\n",
       "      <th>ptugw</th>\n",
       "      <th>allm</th>\n",
       "      <th>allw</th>\n",
       "      <th>ftugt</th>\n",
       "      <th>ptugt</th>\n",
       "      <th>allt</th>\n",
       "      <th>ftmf</th>\n",
       "      <th>ugfrac</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100654</th>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>34.783368</td>\n",
       "      <td>-86.568502</td>\n",
       "      <td>1836</td>\n",
       "      <td>1963</td>\n",
       "      <td>133</td>\n",
       "      <td>119</td>\n",
       "      <td>2268</td>\n",
       "      <td>2752</td>\n",
       "      <td>3799</td>\n",
       "      <td>252</td>\n",
       "      <td>5020</td>\n",
       "      <td>0.483285</td>\n",
       "      <td>0.756773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100663</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>33.502230</td>\n",
       "      <td>-86.809170</td>\n",
       "      <td>3501</td>\n",
       "      <td>4856</td>\n",
       "      <td>1279</td>\n",
       "      <td>1866</td>\n",
       "      <td>7309</td>\n",
       "      <td>11259</td>\n",
       "      <td>8357</td>\n",
       "      <td>3145</td>\n",
       "      <td>18568</td>\n",
       "      <td>0.418930</td>\n",
       "      <td>0.450075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100690</th>\n",
       "      <td>Amridge University</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>32.362609</td>\n",
       "      <td>-86.174010</td>\n",
       "      <td>74</td>\n",
       "      <td>128</td>\n",
       "      <td>52</td>\n",
       "      <td>68</td>\n",
       "      <td>264</td>\n",
       "      <td>367</td>\n",
       "      <td>202</td>\n",
       "      <td>120</td>\n",
       "      <td>631</td>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.320127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100706</th>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>34.722818</td>\n",
       "      <td>-86.638420</td>\n",
       "      <td>2331</td>\n",
       "      <td>1906</td>\n",
       "      <td>846</td>\n",
       "      <td>613</td>\n",
       "      <td>4136</td>\n",
       "      <td>3240</td>\n",
       "      <td>4237</td>\n",
       "      <td>1459</td>\n",
       "      <td>7376</td>\n",
       "      <td>0.550153</td>\n",
       "      <td>0.574431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100724</th>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>32.364317</td>\n",
       "      <td>-86.295677</td>\n",
       "      <td>1975</td>\n",
       "      <td>2897</td>\n",
       "      <td>213</td>\n",
       "      <td>271</td>\n",
       "      <td>2399</td>\n",
       "      <td>3676</td>\n",
       "      <td>4872</td>\n",
       "      <td>484</td>\n",
       "      <td>6075</td>\n",
       "      <td>0.405378</td>\n",
       "      <td>0.801975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     instnm  sector act   latitude   longitud  \\\n",
       "unitid                                                                          \n",
       "100654             Alabama A & M University       1   A  34.783368 -86.568502   \n",
       "100663  University of Alabama at Birmingham       1   A  33.502230 -86.809170   \n",
       "100690                   Amridge University       2   A  32.362609 -86.174010   \n",
       "100706  University of Alabama in Huntsville       1   A  34.722818 -86.638420   \n",
       "100724             Alabama State University       1   A  32.364317 -86.295677   \n",
       "\n",
       "        ftugm  ftugw  ptugm  ptugw  allm   allw  ftugt  ptugt   allt  \\\n",
       "unitid                                                                 \n",
       "100654   1836   1963    133    119  2268   2752   3799    252   5020   \n",
       "100663   3501   4856   1279   1866  7309  11259   8357   3145  18568   \n",
       "100690     74    128     52     68   264    367    202    120    631   \n",
       "100706   2331   1906    846    613  4136   3240   4237   1459   7376   \n",
       "100724   1975   2897    213    271  2399   3676   4872    484   6075   \n",
       "\n",
       "            ftmf    ugfrac  \n",
       "unitid                      \n",
       "100654  0.483285  0.756773  \n",
       "100663  0.418930  0.450075  \n",
       "100690  0.366337  0.320127  \n",
       "100706  0.550153  0.574431  \n",
       "100724  0.405378  0.801975  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[2013].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Faculty and staff\n",
    "\n",
    "IPEDS has three different surveys that deal with faculty and staff:\n",
    "* Instructional staff/Salaries.  This survey is the most complete (in terms of years of availability), but has some significant drawbacks. The 2012 and 2013 surveys have non-instructional staff included, but none of the other years do. The surveys between 2005 and 2011 include people on contracts less than 9 months (*i.e.*, adjuncts) but other years don't. Fringe benefits were included up until 2010, but apparently not after that. Furthermore, 9 and 12 month contracts are reported separately. While there may be some deeply meaningful reason for doing so, it makes things a little more difficult for me.\n",
    "* Fall Staff. Available from 1987 onward in odd years, and every year after 2001. This includes noninstructional staff in a whole host of categories, but doesn't include any salary data.\n",
    "* Employees by Assigned Position. From 2001 on. Has many more categories than either of the others. Includes tenure status but not faculty rank.\n",
    "\n",
    "If I want to cover the whole range of years (which I do), I can get closest by using the first of these, which means largely ignoring noninstructional staff and adjuncts and dealing with the 9/12 month issues.  I'll do that for a first pass, at least.\n",
    "\n",
    "The files seem to come in two flavors: wide and long. The long flavor has a variable for academic rank (and another for contract type) which we can group over.  The wide flavor just has all of the variables in a single row.\n",
    "* wide: 1987, 1989-1998 \n",
    "* long: 1984, 1985, 1999, 2001-2013 \n",
    "* missing: 1986, 1988, 2000\n",
    "\n",
    "We process the long flavor files like the fall enrolment, above.  The wide ones are easier; they're like the institutional characteristics we did first.\n",
    "\n",
    "The last thing to do before we actually process is to decide which columns we want to keep. We have two sexes, between two and four contract durations, six academic ranks (full, associate, assistant, instructor, lecturer, and no rank), and three tenure statuses (tenured, tenure track, and non-tenure track), for a total of up to 144 columns. That's clearly too many, and in fact, some of the years don't have that many.\n",
    "\n",
    "If I ignore tenure status (which isn't reported every year, anyway), and gender distribution (there are people better qualified than I to study diversity issues), and contract length, then I'm down to six categories with two variables each (number of people and salary outlay).  Monthly salary may be a more meaningful number, but I don't really care at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wide format years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wide format\n",
    "# 1987-1997\n",
    "aggregation = {'fullcount':['a4', 'a39', 'a79', 'a114'],\n",
    "               'fulloutlay':['a5', 'a40', 'a80', 'a115'],\n",
    "               'assoccount':['a9', 'a44', 'a84', 'a119'],\n",
    "               'assocoutlay':['a10', 'a45', 'a85', 'a120'],\n",
    "               'assistcount':['a14', 'a49', 'a89', 'a124'],\n",
    "               'assistoutlay':['a15', 'a50', 'a90', 'a125'],\n",
    "               'instrcount':['a19', 'a54', 'a94', 'a129'],\n",
    "               'instroutlay':['a20', 'a55', 'a95', 'a130'],\n",
    "               'lectcount':['a24', 'a59', 'a99', 'a134'],\n",
    "               'lectoutlay':['a25', 'a60', 'a100', 'a135'],\n",
    "               'norankcount':['a29', 'a64', 'a104', 'a139'],\n",
    "               'norankoutlay':['a30', 'a65', 'a105', 'a140']}\n",
    "\n",
    "# 1998\n",
    "agg98 = {'fullcount':['saa014', 'saa084', 'saa164', 'saa234'],\n",
    "         'fulloutlay':['saa015', 'saa085', 'saa165', 'saa235'],\n",
    "         'assoccount':['saa024', 'saa094', 'saa174', 'saa244'],\n",
    "         'assocoutlay':['saa025', 'saa095', 'saa175', 'saa245'],\n",
    "         'assistcount':['saa034', 'saa104', 'saa184', 'saa254'],\n",
    "         'assistoutlay':['saa035', 'saa105', 'saa185', 'saa255'],\n",
    "         'instrcount':['saa044', 'saa114', 'saa194', 'saa264'],\n",
    "         'instroutlay':['saa045', 'saa115', 'saa195', 'saa265'],\n",
    "         'lectcount':['saa054', 'saa124', 'saa204', 'saa274'],\n",
    "         'lectoutlay':['saa055', 'saa125', 'saa205', 'saa275'],\n",
    "         'norankcount':['saa064', 'saa134', 'saa214', 'saa284'],\n",
    "         'norankoutlay':['saa065', 'saa135', 'saa215', 'saa285']}\n",
    "\n",
    "wideyears = {1987: {'csv':'sal1987_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1989: {'csv':'sal1989_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1990: {'csv':'sal90_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1991: {'csv':'sal1991_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1992: {'csv':'sal1992_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1993: {'csv':'sal1993_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1994: {'csv':'sal1994_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1995: {'csv':'sal95_a_1.csv',\n",
    "                   'agg':aggregation},\n",
    "             1996: {'csv':'sal96_a_1.csv',\n",
    "                   'agg':aggregation},\n",
    "             1997: {'csv':'sal97_a.csv',\n",
    "                   'agg':aggregation},\n",
    "             1998: {'csv':'sal98_a.csv',\n",
    "                   'agg':agg98}}\n",
    "\n",
    "def process_wide(csvfile, aggregation):\n",
    "    raw = pd.read_csv(csvfile, encoding='latin-1')\n",
    "    # standardize column names to lowercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    \n",
    "    for aggregated, aggcols in aggregation.items():\n",
    "        prepped[aggregated] = prepped[aggcols].sum(axis=1)\n",
    "    \n",
    "    cooked = pd.DataFrame(prepped, columns=aggregation.keys()).fillna(0)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facultydfs = {}\n",
    "for year, yeardict in wideyears.items():\n",
    "    facultydfs[year] = process_wide('../data/'+yeardict['csv'], yeardict['agg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create empty data frames for missing years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missingyears = [1986, 1988, 2000]\n",
    "for year in missingyears:\n",
    "    facultydfs[year] = pd.DataFrame(columns=aggregation.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do the long format years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg84 = {'count':['saa1', 'saa4'],\n",
    "         'outlay':['saa2', 'saa5'],\n",
    "         'group':'line',\n",
    "         'vals':{'full':[1,8],\n",
    "                 'assoc':[2,9],\n",
    "                 'assist':[3,10],\n",
    "                 'instr':[4,11],\n",
    "                 'lect':[5,12],\n",
    "                 'norank':[6,13]}}\n",
    "\n",
    "# in 1999, the survey separated academic rank and contract length into \n",
    "# two line items\n",
    "agg99 = {'count':['empcntm', 'empcntw'],\n",
    "         'outlay':['outlaym', 'outlayw'],\n",
    "         'group':['contract','arank'],\n",
    "         'vals':{'full':[(1,1), (2,1)],\n",
    "                 'assoc':[(1,2), (2,2)],\n",
    "                 'assist':[(1,3), (2,3)],\n",
    "                 'instr':[(1,4), (2,4)],\n",
    "                 'lect':[(1,5), (2,5)],\n",
    "                 'norank':[(1,6), (2,6)]}}\n",
    "\n",
    "# the only survey available from 2001 is a summary, which doesn't separate women and men.\n",
    "# otherwise, it's the same as 99.\n",
    "agg01 = {'count':['empcount',],\n",
    "         'outlay':['outlays',],\n",
    "         'group':['contract','arank'],\n",
    "         'vals':{'full':[(1,1), (2,1)],\n",
    "                 'assoc':[(1,2), (2,2)],\n",
    "                 'assist':[(1,3), (2,3)],\n",
    "                 'instr':[(1,4), (2,4)],\n",
    "                 'lect':[(1,5), (2,5)],\n",
    "                 'norank':[(1,6), (2,6)]}}\n",
    "\n",
    "# in 2012, the contract length went wide while the academic rank stayed long.\n",
    "# also, contract length was split into four categories instead of two.\n",
    "# fortunately, they also include an aggregated column.\n",
    "agg12 = {'count':['satotlt',],\n",
    "         'outlay':['saoutlt',],\n",
    "         'group':'arank',\n",
    "         'vals':{'full':[1,],\n",
    "                 'assoc':[2,],\n",
    "                 'assist':[3,],\n",
    "                 'instr':[4,],\n",
    "                 'lect':[5,],\n",
    "                 'norank':[6,]}}\n",
    "\n",
    "# long format\n",
    "longyears = {1984:{'csv':'sal1984_a.csv',\n",
    "                   'agg':agg84},\n",
    "             1985:{'csv':'sal1985_a.csv',\n",
    "                   'agg':agg84},\n",
    "             1999:{'csv':'sal1999_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2001:{'csv':'sal2001_a_s.csv',\n",
    "                   'agg':agg01},\n",
    "             2002:{'csv':'sal2002_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2003:{'csv':'sal2003_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2004:{'csv':'sal2004_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2005:{'csv':'sal2005_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2006:{'csv':'sal2006_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2007:{'csv':'sal2007_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2008:{'csv':'sal2008_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2009:{'csv':'sal2009_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2010:{'csv':'sal2010_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2011:{'csv':'sal2011_a.csv',\n",
    "                   'agg':agg99},\n",
    "             2012:{'csv':'sal2012_is.csv',\n",
    "                   'agg':agg12},\n",
    "             2013:{'csv':'sal2013_is.csv',\n",
    "                   'agg':agg12}}\n",
    "\n",
    "\n",
    "def process_long(csvfile, aggregation):\n",
    "    raw = pd.read_csv(csvfile, encoding='latin-1')\n",
    "    # standardize column names to lowercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    \n",
    "    grouped = prepped.groupby(aggregation['group'])\n",
    "    collected = {}\n",
    "    for rank,val in aggregation['vals'].items():\n",
    "        groups = []\n",
    "        for subgroup in val:\n",
    "            groups.append(grouped.get_group(subgroup))\n",
    "            \n",
    "        catted = pd.concat(groups)\n",
    "        unitgroups = catted.groupby(level=0)\n",
    "        collected[rank+\"count\"] = unitgroups.sum()[aggregation['count']].sum(axis=1)\n",
    "        collected[rank+\"outlay\"] = unitgroups.sum()[aggregation['outlay']].sum(axis=1)\n",
    "        \n",
    "    cooked = pd.DataFrame(collected).fillna(0)\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year, yeardict in longyears.items():\n",
    "    facultydfs[year] = process_long('../data/'+yeardict['csv'], yeardict['agg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge into existing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for year, yeardf in dataframes.items():\n",
    "    dataframes[year] = pd.merge(yeardf, facultydfs[year], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finances\n",
    "\n",
    "This is a complicated topic, and I am by no means an expert.  As I see it, there are four important categories of numbers in this section:\n",
    "1. income\n",
    "2. expenses\n",
    "3. assets\n",
    "4. liabilities\n",
    "\n",
    "Unfortunately, the three major types of institution (public, non-profit private, and for-profit private) have significantly different sources of income, and often very different collections of assets and liabilities, as well.  That makes comparisons difficult.  From about 1997 on the three categories of institution have their data in separate files. Before that, the organization of the data is kind of a mess. The first couple years of our range drop everything into a single file, but through most of the 90's, there are a wide array of different files for each year.\n",
    "\n",
    "I'm going to have to select a subset of the possible variables so that I don't drown in them. (There are about 200 different variables for nonprofit institutions in the 2013 data; public institutions (160) and for-profit institutions (40) have fewer). For now, I will focus on six numbers: totals for income, expenses, and debt; amount of income from tuition and fees, value of the endowment at the end of the year, and the amount expended on instructional costs.\n",
    "\n",
    "Assets are kind of a sticky area. Things like land and physical plant are very illiquid, and depend strongly on local market values. On the other hand, for-profit institutions don't have an endowment, as such, but I care less about their finances at this point. If I decide I need some other measure of total assets, or something additional for the for-profit institutions, I'll go back and refactor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping84 = {'allincome':'a20', \n",
    "             'tuitionincome':'a01',\n",
    "             'instructionexpense':'b01',\n",
    "             'totalexpense':'b19',\n",
    "             'debt':'d04',\n",
    "             'endowment':'f64'}\n",
    "\n",
    "# total debt and endowment don't seem to be reported in 88.\n",
    "mapping88 = {'allincome':'a163', \n",
    "             'tuitionincome':'a013',\n",
    "             'instructionexpense':'b013',\n",
    "             'totalexpense':'b223'}\n",
    "\n",
    "single_files = {1984:{'csv':'f1984.csv',\n",
    "                     'mapping':mapping84}\n",
    "               1985:{'csv':'f1985.csv',\n",
    "                     'mapping':mapping84},\n",
    "               1986:{'csv':'f1986.csv',\n",
    "                     'mapping':mapping84},\n",
    "               1988:{'csv':'f1988.csv',\n",
    "                     'mapping':mapping88}}\n",
    "\n",
    "def process_single_financial(csvfile, mapping):\n",
    "    raw = pd.read_csv(csvfile, encoding='latin-1')\n",
    "    # standardize column names to uppercase without leading or trailing whitespace\n",
    "    raw.columns = [colname.strip().lower() for colname in raw.columns]\n",
    "    \n",
    "    # this is present in all of the files\n",
    "    prepped = raw.set_index('unitid')\n",
    "    for key, colname in mapping.items():\n",
    "        prepped[key] = prepped[colname]\n",
    "    cooked = pd.DataFrame(prepped, columns=mapping.keys())\n",
    "    return cooked\n",
    "\n",
    "\n",
    "multi_by_category = {1987:{'f1987_a.csv':{},\n",
    "                           'f1987_b.csv':{'totalexpense':'b223',\n",
    "                                          'instructionexpense':'b013'}},\n",
    "                     1989:{},\n",
    "                     1990:{},\n",
    "                     1991:{},\n",
    "                     1992:{},\n",
    "                     1993:{},\n",
    "                     1994:{},\n",
    "                     1995:{},\n",
    "                     1996{}}\n",
    "\n",
    "\n",
    "\n",
    "multi_by_sector = {1997:{},\n",
    "                   1998:{},\n",
    "                   1999:{},\n",
    "                   2000:{},\n",
    "                   2001:{},\n",
    "                   2002:{},\n",
    "                   2003:{},\n",
    "                   2004:{},\n",
    "                   2005:{},\n",
    "                   2006:{},\n",
    "                   2007:{},\n",
    "                   2008:{},\n",
    "                   2009:{},\n",
    "                   2010:{},\n",
    "                   2011:{},\n",
    "                   2012:{},\n",
    "                   2013:{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1980 = pd.read_csv('../data/f1980.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unitid</th>\n",
       "      <th>a01</th>\n",
       "      <th>a02</th>\n",
       "      <th>a03</th>\n",
       "      <th>a04</th>\n",
       "      <th>a05</th>\n",
       "      <th>a06</th>\n",
       "      <th>a07</th>\n",
       "      <th>a08</th>\n",
       "      <th>a09</th>\n",
       "      <th>...</th>\n",
       "      <th>if53</th>\n",
       "      <th>if54</th>\n",
       "      <th>if55</th>\n",
       "      <th>if56</th>\n",
       "      <th>if61</th>\n",
       "      <th>if62</th>\n",
       "      <th>if63</th>\n",
       "      <th>if64</th>\n",
       "      <th>if65</th>\n",
       "      <th>if66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654</td>\n",
       "      <td>1913906</td>\n",
       "      <td>87672</td>\n",
       "      <td>7935082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5684385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101189</td>\n",
       "      <td>2229728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>732797</td>\n",
       "      <td>0</td>\n",
       "      <td>3963</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101709</td>\n",
       "      <td>1851048</td>\n",
       "      <td>0</td>\n",
       "      <td>5072776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1721006</td>\n",
       "      <td>0</td>\n",
       "      <td>3303</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100724</td>\n",
       "      <td>1799314</td>\n",
       "      <td>0</td>\n",
       "      <td>6950793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2497035</td>\n",
       "      <td>0</td>\n",
       "      <td>47333</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100760</td>\n",
       "      <td>266278</td>\n",
       "      <td>0</td>\n",
       "      <td>1406260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unitid      a01    a02      a03  a04  a05      a06  a07    a08  a09  ...   \\\n",
       "0  100654  1913906  87672  7935082    0    0  5684385    0      0    0  ...    \n",
       "1  101189  2229728      0        0    0    0   732797    0   3963    0  ...    \n",
       "2  101709  1851048      0  5072776    0    0  1721006    0   3303    0  ...    \n",
       "3  100724  1799314      0  6950793    0    0  2497035    0  47333    0  ...    \n",
       "4  100760   266278      0  1406260    0    0   326333    0      0    0  ...    \n",
       "\n",
       "   if53  if54  if55  if56  if61  if62  if63  if64  if65  if66  \n",
       "0     0     0     0     1     0     0     1     0     0     1  \n",
       "1     0     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     1     0     0     0     0     0     1  \n",
       "\n",
       "[5 rows x 197 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1980.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1980['totalin'] = f1980[['a01', 'a02', 'a03', 'a04', 'a05', 'a06', 'a07', 'a08', 'a09', 'a10', 'a11', \n",
    "                         'a12', 'a13', 'a14', 'a15', 'a16', 'a17', 'a18', 'a19']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        33996104\n",
       "1         4329969\n",
       "2        21957718\n",
       "3        33448969\n",
       "4         5232415\n",
       "5         4563507\n",
       "6       145103568\n",
       "7        36272197\n",
       "8        11703299\n",
       "9         3431304\n",
       "10       24032224\n",
       "11       12408997\n",
       "12        4333572\n",
       "13        8401687\n",
       "14       36404170\n",
       "15        3290252\n",
       "16       15477409\n",
       "17        5546764\n",
       "18       19925176\n",
       "19        1571000\n",
       "20        4164148\n",
       "21        6239036\n",
       "22        5222574\n",
       "23        3893441\n",
       "24        5507515\n",
       "25        5131802\n",
       "26        7672185\n",
       "27        2183201\n",
       "28       42868387\n",
       "29        1974647\n",
       "          ...    \n",
       "3159      7417392\n",
       "3160         2100\n",
       "3161       462610\n",
       "3162        34341\n",
       "3163      1842344\n",
       "3164      1921761\n",
       "3165       803896\n",
       "3166       572732\n",
       "3167       345020\n",
       "3168            0\n",
       "3169     26353892\n",
       "3170       458876\n",
       "3171      2074623\n",
       "3172       341695\n",
       "3173      9919150\n",
       "3174      1214230\n",
       "3175      6740573\n",
       "3176      4625796\n",
       "3177       837809\n",
       "3178     14810521\n",
       "3179      5056983\n",
       "3180       345020\n",
       "3181    116000000\n",
       "3182      2504714\n",
       "3183        40966\n",
       "3184     25039531\n",
       "3185        52304\n",
       "3186       227413\n",
       "3187       345020\n",
       "3188      1630766\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1980[['c15', 'c25', 'c35', 'e21']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        21591738\n",
       "1         4567198\n",
       "2        12207803\n",
       "3        14629893\n",
       "4         2185925\n",
       "5         2793608\n",
       "6       128633403\n",
       "7        10105318\n",
       "8         7857075\n",
       "9         3323198\n",
       "10       12666283\n",
       "11        5236439\n",
       "12        3073303\n",
       "13        3309955\n",
       "14       15675009\n",
       "15        1370397\n",
       "16        8298059\n",
       "17        2134959\n",
       "18        5235740\n",
       "19         478216\n",
       "20        2337163\n",
       "21        6354411\n",
       "22        2857362\n",
       "23        4972911\n",
       "24        2465481\n",
       "25        1729875\n",
       "26        8110178\n",
       "27        1191878\n",
       "28       13755645\n",
       "29        1861198\n",
       "          ...    \n",
       "3159       769027\n",
       "3160        77498\n",
       "3161       309878\n",
       "3162        67439\n",
       "3163       616011\n",
       "3164      2001100\n",
       "3165       837085\n",
       "3166       596378\n",
       "3167       359264\n",
       "3168       232962\n",
       "3169      6829149\n",
       "3170       477821\n",
       "3171       934140\n",
       "3172       959866\n",
       "3173       930596\n",
       "3174      1054288\n",
       "3175      2792089\n",
       "3176      3205389\n",
       "3177       698326\n",
       "3178      6296825\n",
       "3179      3476935\n",
       "3180       359264\n",
       "3181     20425113\n",
       "3182       916788\n",
       "3183       228807\n",
       "3184      3560275\n",
       "3185       116594\n",
       "3186       506931\n",
       "3187       359264\n",
       "3188       306900\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1980[['a01', 'a02', 'a03', 'a04', 'a05', 'a06', 'a07', 'a08', 'a09', 'a10', 'a11', \n",
    "                         'a12', 'a13', 'a14', 'a15', 'a16', 'a17', 'a18', 'a19']].sum(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
